<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Academic</title>
    <link>https://example.com/post/</link>
      <atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 19 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://example.com/post/</link>
    </image>
    
    <item>
      <title>Blog Post #6 - Ground Game</title>
      <link>https://example.com/post/blog-post-6-ground-game/</link>
      <pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-6-ground-game/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Throughout the 21st Century, turnout across the United States has fluctuated significantly. For the sake of this blog post, voter turnout is described as the % of the amount of voters vs. the voting eligible population (18+ &amp;amp; have the ability to vote). Taking data from the University of California Santa Barbara’s American Presidency Project, which collects data pertaining to presidential elections, we find that in the 2000 election, voter turnout was just 55.3%. Based on ElectProject.org, in the 2020 election, voter turnout was 66.6%; the highest since the 1900 presidential election.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;However, our focus is on the 2022 midterm elections &amp;amp; understanding the impact of turnout on congressional races. For the sake of context, turnout in 2018 was 50.0%, contrary to 2014’s turnout at 36.7%. Both of these races have something in common: they are midterm elections. Midterm elections rarely rival presidential election turnout — but when they do, elections become significantly more interesting.

The old rule of thumb was that increasing turnout meant an increase in Democratic vote share. Many pundits have been under the assumption that democrats rely heavily on turnout in order to win their elections, whereas republicans are the baseline winners. Taking 2014 &amp;amp; 2018 for instance — 2014 was an overwhelming red wave year, where Democrats were far from enthused &amp;amp; didn’t turnout. 2018, on the other hand, was a significantly high turnout year, in which Democrats won back control of the House of Representatives. Though, it is not that simple.

In this blog, we will be exploring the impact of turnout on the midterm elections, though we will be considering more than just that. In addition to turnout, we will be mapping our data based on expert predictions and incumbency. In this blog post, we will be utilizing 2018 as our data point — given that we are only using data for all 435 districts for 2018. For incumbency, we will be treating that as a factor by congressional district, denoting incumbency by the incumbent party in the district (even if the race is an open seat). Finally, our expert predictions will be taken from the Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;background-on-2018-midterm-elections&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background on 2018 Midterm Elections&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;To start, here are 2 maps of the 2018 midterm election results, as a baseline to see the election results. The first will show the margin of Democratic Party vote share, whereas the other will show the election winner in red or blue.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in sprintf(&amp;quot;https://cdmaps.polisci.ucla.edu/shp/districts114.zip&amp;quot;, :
## one argument not used by format &amp;#39;https://cdmaps.polisci.ucla.edu/shp/
## districts114.zip&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in sprintf(&amp;quot;districtShapes/districts114.shp&amp;quot;, cong): one argument not
## used by format &amp;#39;districtShapes/districts114.shp&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `districts114&amp;#39; from data source 
##   `/private/var/folders/15/62drzq6146bd63l1qfb1btkr0000gn/T/RtmpQG1qdt/districtShapes/districts114.shp&amp;#39; 
##   using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 436 features and 15 fields (with 1 geometry empty)
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -179.1473 ymin: 18.91383 xmax: 179.7785 ymax: 71.35256
## Geodetic CRS:  NAD83&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 16067 Columns: 31
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (16): Office, State, Area, RepCandidate, RepStatus, DemCandidate, DemSta...
## dbl (14): raceYear, RepVotes, DemVotes, ThirdVotes, OtherVotes, PluralityVot...
## lgl  (1): CensusPop
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
## `summarise()` has grouped output by &amp;#39;district_num&amp;#39;, &amp;#39;State&amp;#39;, &amp;#39;district_id&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 22.80 64.41 49.59 50.62 38.84 68.25&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;geojsonlint&amp;#39;:
##   method         from 
##   print.location dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] (0,50]   (50,100] (0,50]   (50,100] (0,50]   (50,100]
## Levels: (0,50] (50,100]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;
Note on the map above: some of the districts are grayed out (only 3), this is due to a data error not being captured by the R code mapping the districts. These are all Republican victories – please view them as such.&lt;/p&gt;
&lt;p&gt;Overall, Democrats captured 235 House seats, to the Republican Party’s 199. This was the most recent midterm election result.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-on-expert-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model on expert prediction&lt;/h2&gt;
&lt;p&gt;Now, we move onto expert predictions for 2018 &amp;amp; see what worked versus did not. Here is a map of the 2018 predictions on the House level.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 7.000000 1.000000 3.666667 3.666667 3.666667 3.666667&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: gridExtra&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;gridExtra&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:dplyr&amp;#39;:
## 
##     combine&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on the results above, we find that expert predictions are not too far off from reality. The results vs. the expected are nearly identitcal – with very similar maps. There are some differences, but ultimately, expert predictions are quite reliable.&lt;/p&gt;
&lt;p&gt;Unfortunately, expert predictions are not always going to be the most “ethical” way to go about political predictions. In a sense, it is cheating, as the factors we include, such as GDP growth, presidential approval, incumbency, etc. are all taken into account through the expert forecasts. Thus, if we create a forecast with 5-10 variables impacting the prediction, while including an expert rating that already does that, we could be over-doing the forecast. Though, expert predictions on its own, could be fascinating to explore.&lt;/p&gt;
&lt;p&gt;Ironically, we are going to move into expert predictions + incumbency as it pertains to Dem vote share.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-including-incumbency-expert-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model including incumbency + expert predictions&lt;/h2&gt;
&lt;p&gt;To begin, let’s explore the correlation between the ratings from political firms &amp;amp; the Democratic Party’s vote share:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Dem_votes_pct ~ avg, data = expertratings)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.557  -7.208  -0.767   5.473  24.972 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  81.7734     0.9238   88.52   &amp;lt;2e-16 ***
## avg          -6.7452     0.1982  -34.04   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 11.05 on 434 degrees of freedom
## Multiple R-squared:  0.7275, Adjusted R-squared:  0.7268 
## F-statistic:  1159 on 1 and 434 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the found R^2 of 0.7275, we can conclude that there is correlation between Democratic Party vote share and expert rating. This correlation indicates that expert ratings are good at providing helpful insight into the outcome of elections on the Congressional level.&lt;/p&gt;
&lt;p&gt;At this point in the blog post, we will be shifting from predictions, to rather analyzing the correlation between our extended variables and the 2018 election results. This is because I do not plan to include any of the future variables in my final prediction – however, knowing how they are connected to Democratic Party vote share is equally fascinating as it is important. Now, let’s throw in the factor of incumbency into the mix in addition to expert predictions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Dem_votes_pct ~ avg + IncumbentParty, data = newdatafr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.948  -6.166  -0.558   5.257  24.224 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)     81.5211     0.9145  89.144  &amp;lt; 2e-16 ***
## avg             -5.7455     0.3667 -15.666  &amp;lt; 2e-16 ***
## IncumbentParty  -6.3544     1.9724  -3.222  0.00137 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 10.92 on 435 degrees of freedom
## Multiple R-squared:  0.7334, Adjusted R-squared:  0.7322 
## F-statistic: 598.4 on 2 and 435 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The R^2 in this was 0.7334, which was an increase from the previous R^2 value under just expert predictions. By adding in the incumbent party (currently holding the seat), the R^2 shows a clear correlation between the two variables when added together. This is to be expected, as mentioned previously, as expert predictions practically cover forecasters on many fronts.&lt;/p&gt;
&lt;p&gt;I expect it to be the same as we add in the factor of turnout.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-including-incumbency-expert-predictions-turnout&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model including incumbency + expert predictions + turnout&lt;/h2&gt;
&lt;p&gt;Before we look at turnout, I want to plot a simple map of turnout by congressional district in 2018, just for additional context.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.43 0.54 0.49 0.49 0.54 0.54&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;
As shown in the map, most congressional districts experienced turnout between 40%-60%. This puts the majority of our districts within a similar turnout rate, thus making it more difficult to use it as a predictor. Despite the majority being 40%-60%, there are some extremely high turnout districts, such as Montana’s At-Large District, with 60%-80% turnout. Some, however, are on the flip side of low turnout: such as Texas’s 34th District, betwene 20%-40%. Main takeaway from this map: turnout is pretty standard when sectioned into blocks.&lt;/p&gt;
&lt;p&gt;Let’s run a linear regression model to find the correlation between Dem vote share &amp;amp; incumbency + turnout + expert predictions! The big 3!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Dem_votes_pct ~ avg + IncumbentParty + turnout, 
##     data = newdatafr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -44.733  -6.700   0.244   5.981  27.275 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)      97.545      2.583  37.757  &amp;lt; 2e-16 ***
## avg              -5.990      0.352 -17.016  &amp;lt; 2e-16 ***
## IncumbentParty   -3.692      1.926  -1.917   0.0558 .  
## turnout         -34.236      5.195  -6.590 1.28e-10 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 10.43 on 434 degrees of freedom
## Multiple R-squared:  0.7577, Adjusted R-squared:  0.756 
## F-statistic: 452.4 on 3 and 434 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above model, the R^2 was found to be 0.756. This is quite significant in terms of correlation, showing how there is a correlation between incumbency, expert predictions, AND turnout. All 3 of the factors increase the correlation between the variables – getting it closer to 1, each time we added a new variable.&lt;/p&gt;
&lt;p&gt;Unfortunately, I will not be using turnout or incumbency in my final prediction, but for my 2022 forecast, I am now considering using expert predictions. Here is my prediction based on that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       50.4
##  2  2022 Arizona   1                       5     4       5.5     4.83       48.9
##  3  2022 Arizona   2                       5     5       5.5     5.17       48.1
##  4  2022 Arizona   4                       3     2       1.75    2.25       55.4
##  5  2022 Arizona   6                       5     5       4.75    4.92       48.7
##  6  2022 Californ… 3                       6     6       6.25    6.08       45.8
##  7  2022 Californ… 6                       1     1       1       1          58.5
##  8  2022 Californ… 9                       3     3       1.75    2.58       54.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        52.3
## 10  2022 Californ… 21                      2     1       1       1.33       57.7
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above chart, you can find the prediction for the 2022 congressional midterms based on expert ratings from the Cook Political Report, Sabato’s Crystal Ball, and Inside Elections.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;p&gt;The limitations of this blog post can be found in a number of ways. On one hand, our data utilizing only the 2018 election restricts the models ability to compare accuracy from previous elections (preferrably 2012-2020). By using 2018, we are restricted to a high-turnout, pro-Democratic party midterm election, rather than assessing a potentially (as 2022 may be) red-wave midterm or low-turnout midterm. However, I do believe that 2018 is closest to the actual district breakdown (some districts are different in the 2014 map) while serving as a basis from a midterm election.&lt;/p&gt;
&lt;p&gt;Another set of limitations deal directly with the sparse amounts of expert predictions &amp;amp; the restriction on the districts provided by the expert prediction data set. The data set provided by the course only has about 140 districts, rather than the traditional 435. On top of that, we narrowed our scope to 3 main forecasters, rather than include many more (the original data set included 10+). Though, I stand by my decision to utilize just the main 3.&lt;/p&gt;
&lt;p&gt;Beyond this, our turnout numbers were also restricted to 2018 – which was one of the midterms with extremely high turnout. In fact, 2018 turnout rivaled presidential election turnout in 2000 + 2004 (by raw vote #). This would be a limitation if 2022 was not expected to be a high-turnout midterm, but given the expected turnout, this was probably an okay decision.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;In conclusion, we can draw a significant connection between expert predictions, incumbency, and turnout to Democratic Party vote share. While this may be expected, we find this to be stated through our R^2 values and the code accompanying this blog post. As I reflect on my own 2022 model, I do not plan to utilize turnout or incumbency, as 1. we do not have turnout numbers for 2022 yet, and 2. incumbency typically matters for the President’s party, not the opposition. To code my model with the same factors would likely have to take a dramatically different form from it’s state in this blog – thus, I will likely not be including it in my final model.&lt;/p&gt;
&lt;p&gt;As for my takeaways &amp;amp; understandings of elections from this blog, I would say there are 3 main things we can takeaway:
1. Democratic party vote share is correlated with all the variables mentioned above
2. Expert predictions covers most of the correlation/connection between Dem vote share + incumbency, turnout, predictions
3. Our blog post was rooted in 2018, and while the turnout may be matched in 2022, this should not be applied to any midterms where turnout is expected to DROP below 2018-levels.&lt;/p&gt;
&lt;p&gt;Thank you for reading :) See you next week!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #4 - Predictions/Forecasts</title>
      <link>https://example.com/post/blog-post-4/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-4/</guid>
      <description>


&lt;p&gt;Expert predictions have been around in election analytics for decades. Predictions of election results have become a new market for various news agencies &amp;amp; websites to gain fame and popularity over correct predictions. Predictions also help inform an electorate of how a race may end up, well before the results are actually in. In the case of this blog post, we are going to be specifically focused on the 2018 midterm elections; we will be exploring the accuracy of the political pundits &amp;amp; what it means for competitive seats in these upcomimg November midterms (2022).&lt;/p&gt;
&lt;p&gt;In this blog, we will be focused on mostly swing/competitive districts for 2022, as described in our data sets. This data will be helpful to explore how accurate or inaccurate some of these experts are at forecasting the race. To narrow our field even more, we will only be utilizing the expert ratings from Inside Elections, Cook Political Report, and Larry Sabato’s Crystal Ball. Interestingly enough, I have actually met one of the leads at the Sabato Crystal Ball &amp;amp; spoke with Dave Wasserman, a head at the Cook Political Report. These are trustworthy forecasters, some of which have nailed past midterms &amp;amp; presidential elections; thus, my intial expectation for the upcoming midterms is that these predictions will be very accurate.&lt;/p&gt;
&lt;p&gt;Additionally, this blog post utilizes a numeric system for ratings, from 1-7. 1 being the safest for the DEMOCRATIC PARTY &amp;amp; 7 being the safest for the REPUBLICAN PARTY. Some ratings in the data set utilize a 9-point scale (traditionally, most use 7), as a result of the inclusion of a new characterization: tilt. However, the dataset accounts for that &amp;amp; has scaled it to work within a 7 point scale. To my knowledge, only Inside Elections uses tilt for House ratings, whereas Cook &amp;amp; Sabato use (only) lean, likely, and safe/solid.&lt;/p&gt;
&lt;div id=&#34;beginning-my-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beginning my code&lt;/h2&gt;
&lt;p&gt;Before we begin, we should model the map of the 2018 midterm elections by Democratic Party voteshare on a district-by-district map. We utilized shape files from the University of California, Los Angeles, to help model our map.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-4/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We are going to compare the map above to what the expert ratings had to say for the map. Unfortunately, we had to cut out Alaska &amp;amp; Hawaii, as it would competely warp our map &amp;amp; make other parts of the map unrecognizable. This means we are modeling 3 less seats than would be traditionally modeled, should Alaska &amp;amp; Hawaii be included. As you can see based on the above map, there are STRONG Democratic pockets across the country, even some with nearly 100% of the vote going towards a Democrat. This is the case in uncontested house seats, where Democrats hold strong &amp;amp; Republicans have no chance at victory. Vice-versa with super bright RED districts, indicating a near 100% victory for the Republican there. Overall though, we see where purple &amp;amp; stronger Democratic share lies, especially on the East &amp;amp; West Coasts, but still support for Democrats throughout the nation.&lt;/p&gt;
&lt;p&gt;Below is the map of the 2018 midterms based on expert prediction.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-4/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
I chose different colors as the range of numbers for the ratings was 0-7, not 0-100 (like the map above this one). This made more sense for visualization &amp;amp; was a good way to track the two different maps.&lt;/p&gt;
&lt;p&gt;To quantify the R^2 value between expert predictions &amp;amp; Democratic Party vote share, I decided to run the lineral regression model to find my number.&lt;/p&gt;
&lt;p&gt;I began launching my code by sorting out the expert ratings for the 3 forecasters (will be referred to as CSI for the remainder of the blog post). I started by following a prediction based strictly on 2018’s forecast accuracy.&lt;/p&gt;
&lt;p&gt;I created a new dataset called “new_train_data_2018”, combining my data sets of the Democratic Party’s vote share in districts &amp;amp; the CSI ratings, all from 2018. This allowed me to use this as my baseline data &amp;amp; run a model to find the correlation between expert prediction and Democratic Vote share.&lt;/p&gt;
&lt;p&gt;The R^2 value was 0.8118 &amp;amp; told me there was a significant connection between the Democratic Party’s vote share &amp;amp; expert ratings. It showed above average accuracy &amp;amp; told me that I could trust my Big 3: Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. Using the 2018 accuracy, I decided to put my CSI to the test in predicting the 2022 midterms.&lt;/p&gt;
&lt;p&gt;Quick reminder: we are only predicting the “competitive” seats as outlined in the dataset.
Here are the 2022 predictions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       50.4
##  2  2022 Arizona   1                       5     4       5.5     4.83       48.9
##  3  2022 Arizona   2                       5     5       5.5     5.17       48.1
##  4  2022 Arizona   4                       3     2       1.75    2.25       55.4
##  5  2022 Arizona   6                       5     5       4.75    4.92       48.7
##  6  2022 Californ… 3                       6     6       6.25    6.08       45.8
##  7  2022 Californ… 6                       1     1       1       1          58.5
##  8  2022 Californ… 9                       3     3       1.75    2.58       54.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        52.3
## 10  2022 Californ… 21                      2     1       1       1.33       57.7
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make things better, I decided to take into account CSI data &amp;amp; accuracy for 2010 through 2018. This meant repeating the above (for 2018), but including 4 more elections! How exciting!&lt;/p&gt;
&lt;p&gt;We calculated the R^2 value of the 2010-2018 connection between prediction &amp;amp; Democratic Party vote share &amp;amp; found it to be 0.7. Not as correlated as 2018, but still pretty good. Then, we calculated 2022 predictions based on 2010-2018 accuracy.&lt;/p&gt;
&lt;p&gt;Here it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       48.1
##  2  2022 Arizona   1                       5     4       5.5     4.83       46.5
##  3  2022 Arizona   2                       5     5       5.5     5.17       45.6
##  4  2022 Arizona   4                       3     2       1.75    2.25       53.5
##  5  2022 Arizona   6                       5     5       4.75    4.92       46.3
##  6  2022 Californ… 3                       6     6       6.25    6.08       43.1
##  7  2022 Californ… 6                       1     1       1       1          56.9
##  8  2022 Californ… 9                       3     3       1.75    2.58       52.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        50.2
## 10  2022 Californ… 21                      2     1       1       1.33       56.0
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Overall, we found that the CSI ratings held up to be pretty good indicators of House elections, especially 2018. I am personally pleased by the result we have seen, but am unsure if I will be including expert ratings in my final forecast. I do think they could help, but I’m deliberating between a FiveThirtyEight-style forecast (in this case, I’d include the expert ratings), or a 2-3 factor model to see if I can accurately predict the midterms without utilizing all variables. Though, this blog post was quite fun, and added a lot to my personal understanding of the connections between punditry and results.&lt;/p&gt;
&lt;p&gt;Thanks for reading :)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #3 - Polling in America</title>
      <link>https://example.com/post/blog-post-3-polling-in-america/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-3-polling-in-america/</guid>
      <description>


&lt;p&gt;Throughout the 21st Century, political punditry and forecasing has been paramount to understanding our national, political environment. Forecasters have used a variety of methods to pinpoint and predict the outcome of future elections. With a significant, recent rise in data analysis, horserace polling, and punditry, election forecasting has risen in popularity as well. Websites such as FiveThirtyEight &amp;amp; the Economist have begun to publish reoccurring election forecasts, depending on the election year. Whether a midterm or presidential election, these sites provide predictions and estimations for both sides of aisle–-backed up by data and statistics.&lt;/p&gt;
&lt;p&gt;To accurately predict an election, however, pundits rely heavily on public, non-partisan polls to fuel their predictions. Polls are typically regarded as the single, most important predictor in any election–at least until 2016. In 2016, the polls were significantly off, dramatically reducing trust in the polling industry. As we move into the 2022 midterm elections, the apprehension behind polls is still apparent, though recent sucesses in 2018 &amp;amp; 2020 have quelled some fears.&lt;/p&gt;
&lt;p&gt;As mentioned above, FiveThirtyEight is a forecasting company that churns out election forecasts in every midterm &amp;amp; presdiential election post-2010, ran by Nate Silver. In their model, they hold many factors to be important in their modeling: basic partisanship, errors found in race-to-race, likely voters, timeline adjustment, house effects adjustment, and present-day issues (such as COVID-19’s impact on voting). They weigh these models using different measures depending on what is most important and accurate within predicting. However, there are significant factors that guide FiveThirtyEight’s forecast towards the right and left wing. These are what we call “fundamentals.” Fundamentals are factors beyond polling that contribute to the race’s outcome.&lt;/p&gt;
&lt;p&gt;Fundamentals can include: an incumbent’s margin of victory in past elections, fundraising, 538’s partisan lean, congressional approval, scandals, voting record, and a challenger’s quality. These factors aide in the decision-making process in FiveThirtyEight’s model, with an emphasis on incumbency (+ performance) and generic ballot polling data. Additionally, FiveThirtyEight utilizes 3 different models for their predictions: Lite (polling + CANTOR), Classic (include fundamentals), Deluxe (include expert forecasts). They weigh their polls &amp;amp; adjust it based on time frame–providing a more accurate prediction.&lt;/p&gt;
&lt;p&gt;G. Elliot Morris runs The Economist’s forecast for elections, relying heavily on their own fundamentals and indicators for their predictions. As we are focused on Congressional (House) elections for 2022, we will be looking at Morris &amp;amp; The Economist’s House Fundamentals: partisan voting history, campaign fundraising, and other factors, similar to FiveThirtyEight. Of course, they utilize the generic ballot as well for their overall indicators. The generic ballot is a shared trait through nearly all pundits and forecasters, as it is a considerable indicator of public support and sentiment towards both parties. We also find that The Economist uses district-level data as part of their fundamentals – FiveThirtyEight does something similar, but it we find both models are hyper-specific. As noted in their 2018 model, The Economist uses a Skew-T distribution.&lt;/p&gt;
&lt;p&gt;As for predictions on the presidential level, The Economist uses economic data (GDP), presidential approval, and more. This data serves as The Economist’s “fundamentals,” as the coined term in FiveThirtyEight’s forecast. Overall, The Economist finds itself weighing similar to FiveThirtyEight (and other forecasters… see DecisionDeskHQ, RaceToTheWhiteHouse, etc.). Though, they have their differences when it comes to weighting and decision-making behind factors to include in their predictions.&lt;/p&gt;
&lt;p&gt;Between the two, I would preference FiveThirtyEight over The Economist. While I do believe that both are relatively accurate forecasters, FiveThirtyEight seems to take into consideration more factors than The Economist. Just through a simple look through of their websites, FiveThirtyEight has more interactive portions of their model that provides the viewer a better understanding of their predictions. Additionally, I prefer the 3 levels of modelling to help compare &amp;amp; contrast predictions from Lite, Classic, and Deluxe. Having the different levels helps me understand the impact of solely polling, then fundamentals included, then finally, expert forecasts.&lt;/p&gt;
&lt;p&gt;In this blog post, we will be utilizing a FiveThirtyEight strategy to understanding the impact of polling &amp;amp; the economy on the midterm elections.&lt;/p&gt;
&lt;p&gt;To begin, we will explore the generic ballot final numbers in November and compare it to the actual results of the midterm election. For this blog post, we will be exploring “Incumbent Party Vote Share.”&lt;/p&gt;
&lt;div id=&#34;generic-ballot-value-vs-actual-over-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generic Ballot Value vs Actual Over Time&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the above graph, we find that there is a correlation between November polling data &amp;amp; final results for political parties. The question is… how strong is the correlation? To find this, we calculated the linear regression model of the relationship between incumbent president’s party vote &amp;amp; the incumbent president’s party polls in November, we find the R squared value to be 0.5843. This reveals we have a moderate relationship between the two variables, thus making the November polls a somewhat accurate predictor of the actual election.&lt;/p&gt;
&lt;p&gt;Following our finding of this moderate relationship, we decided to predict the 2022 midterms based on the Democratic Party’s current numbers in the FiveThirtyEight generic ballot. To set up this prediction, we used the model that formed the above graph, and included a new data frame of the Democratic Party’s numbers as of right now. The current D Party vote share in the generic ballot is 45.3%, and thus, we will use that as our input to predict the actual Democratic Party vote share. When using the model &amp;amp; the new input, we find our prediction to put the Democrats at 49.42% for the 2022 vote-share. This is an under performance from their popular vote share from 2018 &amp;amp; 2020, which we can likely conclude results in a democratic loss in the House this November.&lt;/p&gt;
&lt;p&gt;Now, we will look at the economy.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moving-onto-economic-impacts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Moving onto Economic Impacts&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;
To use economic data, I decided to use GDP growth in the 2nd quarter of the year, to help us better match where the 2022 midterms currently are. Based on the 2nd quarter GDP growth, we created a linear regression model of the relationship between that same GDP growth percentage &amp;amp; the incumbent president’s vote share. In addition to the linear regression model, we created a graph to show the relationship between the variables. In both the visual &amp;amp; calculated linear regression R^2 value, we found no correlation between the two.&lt;/p&gt;
&lt;p&gt;The R-squared value was -0.012, and thus, is actually predicting worse than a standard line. As a result, we likely cannot rely on GDP growth as a means of predicting the midterm elections, as it does us a disservice. However, for the sake of it, we will calculate the expectation for Democrats based on the 2022 Quarter 2’s GDP growth (-0.9%). With this number, the model predicts Democrats will have 48.02% of the vote share. The economy can serve as an equivalent to one of FiveThrityEight’s “fundamentals.”&lt;/p&gt;
&lt;p&gt;Finally, we will combine both factors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;combined-economic-polling-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combined Economic + Polling Model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
After combining both factors, we found the strength to return to a moderate correlation. The R-squared value was found to be 0.57, but this is largely led by the relationship between polling and actual numbers, rather than GDP. Having less of an R-squared value with BOTH variables added in than with JUST polling likely indicates GDP growth was detrimental to my model. In this combined model, it found that the Democratic Party’s expected vote share is 49.37%, not too far off either of the other models. However, I have some difficulty trusting the combined model, as GDP growth is certainly not the best variable for predicting the midterms.&lt;/p&gt;
&lt;p&gt;In conclusion, we have 3 main takeaways from this blog post:
1. Polls in November are pretty good at predicting the actual vote share in the election
2. GDP growth in quarter 2 isn’t good at predicting the actual vote share in the election
3. Democrats still likely lose the House based on all 3 of the models created&lt;/p&gt;
&lt;p&gt;As we move forward, I am looking to change my economic variables to make the model more accurate, or consider entirely scrapping it from the final model.&lt;/p&gt;
&lt;p&gt;Thank you for reading :)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #1</title>
      <link>https://example.com/post/blog-post-2/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-2/</guid>
      <description>


&lt;p&gt;===== Worked with: Claire, Amiel, Jen, Julia &amp;amp; asked Kiara for help =======&lt;/p&gt;
&lt;p&gt;In this blog post, we are going to explore the impact of political gerrymandering on the 2020 House of Representative elections. This blog post will contain 2 main graphics: Figure 1. The 2020 Seat Share Margin Across Each State &amp;amp; Figure 2. The 2020 Party Vote Margin Across Each State. The data we utilized has come from 2 main sources: 1. Lab data from the Gov 1347 class &amp;amp; 2. CQ Voting and Elections Collection.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-2/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;
To begin, we will look at the 2020 vote share margin across the country. The party vote share across the majority of states seems quite tame, however that is likely due to the vote share margin being such an expansive (-0.75, 0.75). The reason for the reduction in the vote share margin frame is because it is rare for a party to get anywhere close to 100% more of the vote than their opponents – as a result, I decided to utilize a range that is more possible (75% vote margin). However, you may notice South Dakota to be gray, this is because the Democrats did not run a candidate in 2020. It is fascinating to think about the fact South Dakota had a Democrat in Congress as recently as 2011. Just food for thought&lt;/p&gt;
&lt;p&gt;Our vote share map reveals that some states are pretty close by House vote share: NC, VA, GA, FL, AZ, NV, PA, MI, WI, IA, MN, and NH (among others). These, not by coincidence, happened to be swing states in the presidential election that coincided with these House elections. The takeaway from this map is that more-states-than-not are close and competitive on the vote-share side. So… from this, you’d expect it to be similar in terms of House Composition/Seat Share? Right?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-2/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;
Wrong. When we find the seat share margin map, we find that the majority of states have a extreme partisan compositions, whether that be for Republicans or Democrats. Innocently, we could think that this could be due to simple partisanship, but we saw how few states were truly extremely partisan. For example Maryland–which hasn’t voted for a Republican since 1984 (U.S. Election Atlas)–is heavily blue on our shaded map on both the vote share &amp;amp; seat share map, but this is not the case for many other states. Plainly put: Maryland is an outlier.&lt;/p&gt;
&lt;p&gt;Some major differences between vote marign and seat margin can be found in many, many states, but most notably Texas, Ohio, and the worst of all, North Carolina. Texas and Ohio have significantly redder compositions on the Seat Share margin map than on the Party Vote Margin. If you look at the actual party vote margin in Ohio, it is 52R-47D (Ohio Secretary of State Website), compared to the seat composition of 12R-4D (OH SOS). This is a prime example of extreme gerrymandering. Sadly, Ohio is not alone. Texas is another example of partisan gerrymandering, where Republicans won just 9 points more than the Democrats statewide (Texas Secretary of State Website), yet lead them 23-13 (TX SOS) in the House composition. The worst example on the map would have to be North Carolina, where Democrats won the popular vote, yet only won 5/13 House seats in the state. This extreme level of gerrymandering prevented the Democrats from winning a majority in North Carolina.&lt;/p&gt;
&lt;p&gt;To clarify some important parts of the seat share margin map: some states have one singular district, meaning that the result will always be one dark color on the seatshare margin map. For instance, Montana has 1 Representative, and though Republicans won by less than 15%, it still went to them, thus marking the map as solid red. To not confuse single-district states with gerrymandered ones, here are the single-district states in the United States (pre-2022 Redistricting Era): AK, DE, MT, ND, SD, VT, and WY.&lt;/p&gt;
&lt;p&gt;In conclusion, I could write on and on about the abundance of evidence of gerrymandering through our maps, but it would be ultimately be redundant. To wrap up, there are two main takeaways that this blog post has revealed: 1. Republicans gerrymander better than Democrats – or at least, have more gerrymandered states than Democrats, likely due to their heavy levels of victories back in 2010 (see: 2010 Election Results) – and it shows. &amp;amp; 2. Vote share and seat share does align in some states, showcasing that our system is not entirely screwed up.&lt;/p&gt;
&lt;p&gt;Altogether, our political system in the House of Representatives needs work to ensure fair representation. However, based on how engrained gerrymandering is in American political culture – I am far from hopeful.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #1</title>
      <link>https://example.com/post/blog-post-1/</link>
      <pubDate>Tue, 13 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-1/</guid>
      <description>


&lt;p&gt;Question/Blog Extension we are going to be going through:
Heterogenous Predictive Power of the Economy.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Does the effect of the economy vary when we consider popular vote versus seat share as our outcome (dependent) variable?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Does the predictive power of economy change across time? If so, why?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To begin, this blog post will be dealing with data sets that have been filtered and combined through R. This blog post will be utilizing GDP Quarter 7 data from the midterm years 1962-2018. By my own discretion, I have removed the presidential election years, as the data set does not treat the “president_party” variable as the party going into the election, but rather the victor of the presidential election. Consequently, I felt it would be most beneficial if that was taken out of the equation for this blog post. Additionally, as this class is focused on the 2022 midterms, I hoped to utilize the midterm-only data to guage a better understanding of midterms.&lt;/p&gt;
&lt;p&gt;To sort our data, I combined economic data and House of Representatives election data. In addition, we filtered, then mutated the data to create two new variables within our blog: pres_party_seat_share and pres_party_vote_share. The seat share was defined as the # of seats for the president’s party divided by 435 (total # of seats in the U.S. House). This also explains the reasoning behind the year selection, beginning in 1960, as that was the first year in history with 435 House seats (following Hawaii &amp;amp; Alaska’s addition to the United States).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
With this data, we first created a scatterplot based on the “Quarter 7 GDP Growth” and “President’s Party Seat Share.” GDP growth in Quarter 7 was chosen as the most recent quarter leading into an election. The expectation was that a recent bump (or lackthereof) in the economy would either benefit/hinder the president’s party in seat share (similar to what we read in Healy and Lenz || &amp;amp; Achens). To test, we formed the scatterplot while placing a linear regression model line on the graph itself.&lt;/p&gt;
&lt;p&gt;My personal expectations were that GDP growth would result in president’s party seat share being nearly 50% or above. Unfortunately, the model did not find the GDP growth and party seat share to follow my expectations. There were numerous instances where the president’s party’s seat share was below 50%, despite the GDP growth being around 1% or even more. Whenever the GDP growth was negative, the president’s party never received above 50% of the seat share.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
Then, we moved on to see if the president’s party’s vote share was more reflective than seat share, as described by the blog extension. When we ran the model, we did not find it to be particularly accurate, but there were instances (similar to seat share) of accuracy. Again, the economy and seat share relationship did not match expectations to the extent that was originally thought. Though similar to the president’s party seat share, it did reveal that there was not one instance where a president’s party won the majority of the popular vote when GDP growth was negative. This made sense.&lt;/p&gt;
&lt;p&gt;Then, we aimed to calculate the actual linear regression number on the GDP growth pct as it relates to president’s party vote vote share &amp;amp; president’s party seat share.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
To begin, we looked at the relationship at a quantified relationship between pres_party_vote_share and GDP_growth_pct. We found the calculation to be 3.65, thus indicating that for every 1% increase in GDP, we can expect the president’s party vote share to increase by 3.65%. I do think this number could be defending in traditional election circumstances, but the 15 midterm years we are utilizing for analysis make me somewhat uncertain about this. If I had the ability, I would use data from past midterms well beyond 1962, given that I had additional time &amp;amp; data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;
We then ran the other calculation. Our calculations found a value of 8.174 between a lm calculation of pres_party_seat_share and GDP_growth_pct. This means that for every 1% increase in GDP, we could expect an 8.17% increase in pres party’s seat share. However, I do not buy this number. This is such a large number that simply does not make much sense in the modern political world. A 1% increase will likely not result in an 8% increase in future elections, especially midterm ones with many more factors than the economy. While an interesting finding, I do not know if I trust it entirely. Similar to above, I would also wish to explore this with additional time &amp;amp; resources.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;672&#34; /&gt;
The second part of this blog extension is to see if there is a change in accuracy over time in these elections. Plainly put: there does not appear to be.&lt;/p&gt;
&lt;p&gt;To determine this, we utilized a plot that mapped both a predicted model (based on our data) and the actual model. The party vote share based on actual results vs predicted results did find some spot-on accuracies in the elections of: 1974, 1982, 1990, and 2008. There were also some close calls, but on the overall, it was not nearly as predicitive as it could’ve been. Given the range of accuracy/innacuracies across the time frame, I believe that there is not a significant difference overtime.&lt;/p&gt;
&lt;p&gt;When applying this to seat share, predicted vs actual, there were spot on predictions but also many that missed the mark. Generally, there were not many points of consistent accuracy or consistent inaccuracies, as accuracy was a variety across the board.&lt;/p&gt;
&lt;p&gt;Main takeaways:
GDP growth does not seem to be the most predicitve/accurate indicator for a president’s seat growth or vote share
“It’s the economy, stupid.” may not be as true as we think
Time did not help the accuracy/predictive ability of our models&lt;/p&gt;
&lt;p&gt;Sources:
1. Achen and Bartels (2017)
2. Healy and Lenz (2014)
3. I did not use Wright as there was no unemployment calculations.&lt;/p&gt;
&lt;p&gt;Data being used:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;GDP growth (national): 1947-2022 (US Bureau of Economic Analysis, Department of Commerce)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Real disposable income (national): 1959-2022 (US Bureau of Economic Analysis)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inflation – CPI (national): 1947-2022 (US Bureau of Labor Statistics, Department of Labor)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unemployment (national): 1948-2022 (US Bureau of Labor Statistics)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unemployment (state): 1976-2022 (US Bureau of Labor Statistics)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
