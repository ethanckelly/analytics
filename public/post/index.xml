<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Academic</title>
    <link>https://example.com/post/</link>
      <atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 19 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://example.com/post/</link>
    </image>
    
    <item>
      <title>Blog Post #6 - Ground Game</title>
      <link>https://example.com/post/blog-post-6-ground-game/</link>
      <pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-6-ground-game/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;[copy in from Google Doc]&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;background-info-on-turnout&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background Info on Turnout&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;model-on-expert-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model on expert prediction&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;model-including-incumbency-expert-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model including incumbency + expert predictions&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;model-including-incumbency-expert-predictions-turnout&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model including incumbency + expert predictions + turnout&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;poll-only-district-level-linear-regression-vs.-binomial-logistic-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Poll-only district-level linear regression vs. binomial logistic predictions&lt;/h2&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #4 - Predictions/Forecasts</title>
      <link>https://example.com/post/blog-post-4/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-4/</guid>
      <description>


&lt;p&gt;Expert predictions have been around in election analytics for decades. Predictions of election results have become a new market for various news agencies &amp;amp; websites to gain fame and popularity over correct predictions. Predictions also help inform an electorate of how a race may end up, well before the results are actually in. In the case of this blog post, we are going to be specifically focused on the 2018 midterm elections; we will be exploring the accuracy of the political pundits &amp;amp; what it means for competitive seats in these upcomimg November midterms (2022).&lt;/p&gt;
&lt;p&gt;In this blog, we will be focused on mostly swing/competitive districts for 2022, as described in our data sets. This data will be helpful to explore how accurate or inaccurate some of these experts are at forecasting the race. To narrow our field even more, we will only be utilizing the expert ratings from Inside Elections, Cook Political Report, and Larry Sabato’s Crystal Ball. Interestingly enough, I have actually met one of the leads at the Sabato Crystal Ball &amp;amp; spoke with Dave Wasserman, a head at the Cook Political Report. These are trustworthy forecasters, some of which have nailed past midterms &amp;amp; presidential elections; thus, my intial expectation for the upcoming midterms is that these predictions will be very accurate.&lt;/p&gt;
&lt;p&gt;Additionally, this blog post utilizes a numeric system for ratings, from 1-7. 1 being the safest for the DEMOCRATIC PARTY &amp;amp; 7 being the safest for the REPUBLICAN PARTY. Some ratings in the data set utilize a 9-point scale (traditionally, most use 7), as a result of the inclusion of a new characterization: tilt. However, the dataset accounts for that &amp;amp; has scaled it to work within a 7 point scale. To my knowledge, only Inside Elections uses tilt for House ratings, whereas Cook &amp;amp; Sabato use (only) lean, likely, and safe/solid.&lt;/p&gt;
&lt;div id=&#34;beginning-my-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beginning my code&lt;/h2&gt;
&lt;p&gt;Before we begin, we should model the map of the 2018 midterm elections by Democratic Party voteshare on a district-by-district map. We utilized shape files from the University of California, Los Angeles, to help model our map.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-4/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We are going to compare the map above to what the expert ratings had to say for the map. Unfortunately, we had to cut out Alaska &amp;amp; Hawaii, as it would competely warp our map &amp;amp; make other parts of the map unrecognizable. This means we are modeling 3 less seats than would be traditionally modeled, should Alaska &amp;amp; Hawaii be included. As you can see based on the above map, there are STRONG Democratic pockets across the country, even some with nearly 100% of the vote going towards a Democrat. This is the case in uncontested house seats, where Democrats hold strong &amp;amp; Republicans have no chance at victory. Vice-versa with super bright RED districts, indicating a near 100% victory for the Republican there. Overall though, we see where purple &amp;amp; stronger Democratic share lies, especially on the East &amp;amp; West Coasts, but still support for Democrats throughout the nation.&lt;/p&gt;
&lt;p&gt;Below is the map of the 2018 midterms based on expert prediction.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-4/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
I chose different colors as the range of numbers for the ratings was 0-7, not 0-100 (like the map above this one). This made more sense for visualization &amp;amp; was a good way to track the two different maps.&lt;/p&gt;
&lt;p&gt;To quantify the R^2 value between expert predictions &amp;amp; Democratic Party vote share, I decided to run the lineral regression model to find my number.&lt;/p&gt;
&lt;p&gt;I began launching my code by sorting out the expert ratings for the 3 forecasters (will be referred to as CSI for the remainder of the blog post). I started by following a prediction based strictly on 2018’s forecast accuracy.&lt;/p&gt;
&lt;p&gt;I created a new dataset called “new_train_data_2018”, combining my data sets of the Democratic Party’s vote share in districts &amp;amp; the CSI ratings, all from 2018. This allowed me to use this as my baseline data &amp;amp; run a model to find the correlation between expert prediction and Democratic Vote share.&lt;/p&gt;
&lt;p&gt;The R^2 value was 0.8118 &amp;amp; told me there was a significant connection between the Democratic Party’s vote share &amp;amp; expert ratings. It showed above average accuracy &amp;amp; told me that I could trust my Big 3: Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. Using the 2018 accuracy, I decided to put my CSI to the test in predicting the 2022 midterms.&lt;/p&gt;
&lt;p&gt;Quick reminder: we are only predicting the “competitive” seats as outlined in the dataset.
Here are the 2022 predictions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       50.4
##  2  2022 Arizona   1                       5     4       5.5     4.83       48.9
##  3  2022 Arizona   2                       5     5       5.5     5.17       48.1
##  4  2022 Arizona   4                       3     2       1.75    2.25       55.4
##  5  2022 Arizona   6                       5     5       4.75    4.92       48.7
##  6  2022 Californ… 3                       6     6       6.25    6.08       45.8
##  7  2022 Californ… 6                       1     1       1       1          58.5
##  8  2022 Californ… 9                       3     3       1.75    2.58       54.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        52.3
## 10  2022 Californ… 21                      2     1       1       1.33       57.7
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make things better, I decided to take into account CSI data &amp;amp; accuracy for 2010 through 2018. This meant repeating the above (for 2018), but including 4 more elections! How exciting!&lt;/p&gt;
&lt;p&gt;We calculated the R^2 value of the 2010-2018 connection between prediction &amp;amp; Democratic Party vote share &amp;amp; found it to be 0.7. Not as correlated as 2018, but still pretty good. Then, we calculated 2022 predictions based on 2010-2018 accuracy.&lt;/p&gt;
&lt;p&gt;Here it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       48.1
##  2  2022 Arizona   1                       5     4       5.5     4.83       46.5
##  3  2022 Arizona   2                       5     5       5.5     5.17       45.6
##  4  2022 Arizona   4                       3     2       1.75    2.25       53.5
##  5  2022 Arizona   6                       5     5       4.75    4.92       46.3
##  6  2022 Californ… 3                       6     6       6.25    6.08       43.1
##  7  2022 Californ… 6                       1     1       1       1          56.9
##  8  2022 Californ… 9                       3     3       1.75    2.58       52.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        50.2
## 10  2022 Californ… 21                      2     1       1       1.33       56.0
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Overall, we found that the CSI ratings held up to be pretty good indicators of House elections, especially 2018. I am personally pleased by the result we have seen, but am unsure if I will be including expert ratings in my final forecast. I do think they could help, but I’m deliberating between a FiveThirtyEight-style forecast (in this case, I’d include the expert ratings), or a 2-3 factor model to see if I can accurately predict the midterms without utilizing all variables. Though, this blog post was quite fun, and added a lot to my personal understanding of the connections between punditry and results.&lt;/p&gt;
&lt;p&gt;Thanks for reading :)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #3 - Polling in America</title>
      <link>https://example.com/post/blog-post-3-polling-in-america/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-3-polling-in-america/</guid>
      <description>


&lt;p&gt;Throughout the 21st Century, political punditry and forecasing has been paramount to understanding our national, political environment. Forecasters have used a variety of methods to pinpoint and predict the outcome of future elections. With a significant, recent rise in data analysis, horserace polling, and punditry, election forecasting has risen in popularity as well. Websites such as FiveThirtyEight &amp;amp; the Economist have begun to publish reoccurring election forecasts, depending on the election year. Whether a midterm or presidential election, these sites provide predictions and estimations for both sides of aisle–-backed up by data and statistics.&lt;/p&gt;
&lt;p&gt;To accurately predict an election, however, pundits rely heavily on public, non-partisan polls to fuel their predictions. Polls are typically regarded as the single, most important predictor in any election–at least until 2016. In 2016, the polls were significantly off, dramatically reducing trust in the polling industry. As we move into the 2022 midterm elections, the apprehension behind polls is still apparent, though recent sucesses in 2018 &amp;amp; 2020 have quelled some fears.&lt;/p&gt;
&lt;p&gt;As mentioned above, FiveThirtyEight is a forecasting company that churns out election forecasts in every midterm &amp;amp; presdiential election post-2010, ran by Nate Silver. In their model, they hold many factors to be important in their modeling: basic partisanship, errors found in race-to-race, likely voters, timeline adjustment, house effects adjustment, and present-day issues (such as COVID-19’s impact on voting). They weigh these models using different measures depending on what is most important and accurate within predicting. However, there are significant factors that guide FiveThirtyEight’s forecast towards the right and left wing. These are what we call “fundamentals.” Fundamentals are factors beyond polling that contribute to the race’s outcome.&lt;/p&gt;
&lt;p&gt;Fundamentals can include: an incumbent’s margin of victory in past elections, fundraising, 538’s partisan lean, congressional approval, scandals, voting record, and a challenger’s quality. These factors aide in the decision-making process in FiveThirtyEight’s model, with an emphasis on incumbency (+ performance) and generic ballot polling data. Additionally, FiveThirtyEight utilizes 3 different models for their predictions: Lite (polling + CANTOR), Classic (include fundamentals), Deluxe (include expert forecasts). They weigh their polls &amp;amp; adjust it based on time frame–providing a more accurate prediction.&lt;/p&gt;
&lt;p&gt;G. Elliot Morris runs The Economist’s forecast for elections, relying heavily on their own fundamentals and indicators for their predictions. As we are focused on Congressional (House) elections for 2022, we will be looking at Morris &amp;amp; The Economist’s House Fundamentals: partisan voting history, campaign fundraising, and other factors, similar to FiveThirtyEight. Of course, they utilize the generic ballot as well for their overall indicators. The generic ballot is a shared trait through nearly all pundits and forecasters, as it is a considerable indicator of public support and sentiment towards both parties. We also find that The Economist uses district-level data as part of their fundamentals – FiveThirtyEight does something similar, but it we find both models are hyper-specific. As noted in their 2018 model, The Economist uses a Skew-T distribution.&lt;/p&gt;
&lt;p&gt;As for predictions on the presidential level, The Economist uses economic data (GDP), presidential approval, and more. This data serves as The Economist’s “fundamentals,” as the coined term in FiveThirtyEight’s forecast. Overall, The Economist finds itself weighing similar to FiveThirtyEight (and other forecasters… see DecisionDeskHQ, RaceToTheWhiteHouse, etc.). Though, they have their differences when it comes to weighting and decision-making behind factors to include in their predictions.&lt;/p&gt;
&lt;p&gt;Between the two, I would preference FiveThirtyEight over The Economist. While I do believe that both are relatively accurate forecasters, FiveThirtyEight seems to take into consideration more factors than The Economist. Just through a simple look through of their websites, FiveThirtyEight has more interactive portions of their model that provides the viewer a better understanding of their predictions. Additionally, I prefer the 3 levels of modelling to help compare &amp;amp; contrast predictions from Lite, Classic, and Deluxe. Having the different levels helps me understand the impact of solely polling, then fundamentals included, then finally, expert forecasts.&lt;/p&gt;
&lt;p&gt;In this blog post, we will be utilizing a FiveThirtyEight strategy to understanding the impact of polling &amp;amp; the economy on the midterm elections.&lt;/p&gt;
&lt;p&gt;To begin, we will explore the generic ballot final numbers in November and compare it to the actual results of the midterm election. For this blog post, we will be exploring “Incumbent Party Vote Share.”&lt;/p&gt;
&lt;div id=&#34;generic-ballot-value-vs-actual-over-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generic Ballot Value vs Actual Over Time&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the above graph, we find that there is a correlation between November polling data &amp;amp; final results for political parties. The question is… how strong is the correlation? To find this, we calculated the linear regression model of the relationship between incumbent president’s party vote &amp;amp; the incumbent president’s party polls in November, we find the R squared value to be 0.5843. This reveals we have a moderate relationship between the two variables, thus making the November polls a somewhat accurate predictor of the actual election.&lt;/p&gt;
&lt;p&gt;Following our finding of this moderate relationship, we decided to predict the 2022 midterms based on the Democratic Party’s current numbers in the FiveThirtyEight generic ballot. To set up this prediction, we used the model that formed the above graph, and included a new data frame of the Democratic Party’s numbers as of right now. The current D Party vote share in the generic ballot is 45.3%, and thus, we will use that as our input to predict the actual Democratic Party vote share. When using the model &amp;amp; the new input, we find our prediction to put the Democrats at 49.42% for the 2022 vote-share. This is an under performance from their popular vote share from 2018 &amp;amp; 2020, which we can likely conclude results in a democratic loss in the House this November.&lt;/p&gt;
&lt;p&gt;Now, we will look at the economy.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moving-onto-economic-impacts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Moving onto Economic Impacts&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;
To use economic data, I decided to use GDP growth in the 2nd quarter of the year, to help us better match where the 2022 midterms currently are. Based on the 2nd quarter GDP growth, we created a linear regression model of the relationship between that same GDP growth percentage &amp;amp; the incumbent president’s vote share. In addition to the linear regression model, we created a graph to show the relationship between the variables. In both the visual &amp;amp; calculated linear regression R^2 value, we found no correlation between the two.&lt;/p&gt;
&lt;p&gt;The R-squared value was -0.012, and thus, is actually predicting worse than a standard line. As a result, we likely cannot rely on GDP growth as a means of predicting the midterm elections, as it does us a disservice. However, for the sake of it, we will calculate the expectation for Democrats based on the 2022 Quarter 2’s GDP growth (-0.9%). With this number, the model predicts Democrats will have 48.02% of the vote share. The economy can serve as an equivalent to one of FiveThrityEight’s “fundamentals.”&lt;/p&gt;
&lt;p&gt;Finally, we will combine both factors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;combined-economic-polling-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combined Economic + Polling Model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
After combining both factors, we found the strength to return to a moderate correlation. The R-squared value was found to be 0.57, but this is largely led by the relationship between polling and actual numbers, rather than GDP. Having less of an R-squared value with BOTH variables added in than with JUST polling likely indicates GDP growth was detrimental to my model. In this combined model, it found that the Democratic Party’s expected vote share is 49.37%, not too far off either of the other models. However, I have some difficulty trusting the combined model, as GDP growth is certainly not the best variable for predicting the midterms.&lt;/p&gt;
&lt;p&gt;In conclusion, we have 3 main takeaways from this blog post:
1. Polls in November are pretty good at predicting the actual vote share in the election
2. GDP growth in quarter 2 isn’t good at predicting the actual vote share in the election
3. Democrats still likely lose the House based on all 3 of the models created&lt;/p&gt;
&lt;p&gt;As we move forward, I am looking to change my economic variables to make the model more accurate, or consider entirely scrapping it from the final model.&lt;/p&gt;
&lt;p&gt;Thank you for reading :)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #1</title>
      <link>https://example.com/post/blog-post-2/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-2/</guid>
      <description>


&lt;p&gt;===== Worked with: Claire, Amiel, Jen, Julia &amp;amp; asked Kiara for help =======&lt;/p&gt;
&lt;p&gt;In this blog post, we are going to explore the impact of political gerrymandering on the 2020 House of Representative elections. This blog post will contain 2 main graphics: Figure 1. The 2020 Seat Share Margin Across Each State &amp;amp; Figure 2. The 2020 Party Vote Margin Across Each State. The data we utilized has come from 2 main sources: 1. Lab data from the Gov 1347 class &amp;amp; 2. CQ Voting and Elections Collection.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-2/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;
To begin, we will look at the 2020 vote share margin across the country. The party vote share across the majority of states seems quite tame, however that is likely due to the vote share margin being such an expansive (-0.75, 0.75). The reason for the reduction in the vote share margin frame is because it is rare for a party to get anywhere close to 100% more of the vote than their opponents – as a result, I decided to utilize a range that is more possible (75% vote margin). However, you may notice South Dakota to be gray, this is because the Democrats did not run a candidate in 2020. It is fascinating to think about the fact South Dakota had a Democrat in Congress as recently as 2011. Just food for thought&lt;/p&gt;
&lt;p&gt;Our vote share map reveals that some states are pretty close by House vote share: NC, VA, GA, FL, AZ, NV, PA, MI, WI, IA, MN, and NH (among others). These, not by coincidence, happened to be swing states in the presidential election that coincided with these House elections. The takeaway from this map is that more-states-than-not are close and competitive on the vote-share side. So… from this, you’d expect it to be similar in terms of House Composition/Seat Share? Right?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-2/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;
Wrong. When we find the seat share margin map, we find that the majority of states have a extreme partisan compositions, whether that be for Republicans or Democrats. Innocently, we could think that this could be due to simple partisanship, but we saw how few states were truly extremely partisan. For example Maryland–which hasn’t voted for a Republican since 1984 (U.S. Election Atlas)–is heavily blue on our shaded map on both the vote share &amp;amp; seat share map, but this is not the case for many other states. Plainly put: Maryland is an outlier.&lt;/p&gt;
&lt;p&gt;Some major differences between vote marign and seat margin can be found in many, many states, but most notably Texas, Ohio, and the worst of all, North Carolina. Texas and Ohio have significantly redder compositions on the Seat Share margin map than on the Party Vote Margin. If you look at the actual party vote margin in Ohio, it is 52R-47D (Ohio Secretary of State Website), compared to the seat composition of 12R-4D (OH SOS). This is a prime example of extreme gerrymandering. Sadly, Ohio is not alone. Texas is another example of partisan gerrymandering, where Republicans won just 9 points more than the Democrats statewide (Texas Secretary of State Website), yet lead them 23-13 (TX SOS) in the House composition. The worst example on the map would have to be North Carolina, where Democrats won the popular vote, yet only won 5/13 House seats in the state. This extreme level of gerrymandering prevented the Democrats from winning a majority in North Carolina.&lt;/p&gt;
&lt;p&gt;To clarify some important parts of the seat share margin map: some states have one singular district, meaning that the result will always be one dark color on the seatshare margin map. For instance, Montana has 1 Representative, and though Republicans won by less than 15%, it still went to them, thus marking the map as solid red. To not confuse single-district states with gerrymandered ones, here are the single-district states in the United States (pre-2022 Redistricting Era): AK, DE, MT, ND, SD, VT, and WY.&lt;/p&gt;
&lt;p&gt;In conclusion, I could write on and on about the abundance of evidence of gerrymandering through our maps, but it would be ultimately be redundant. To wrap up, there are two main takeaways that this blog post has revealed: 1. Republicans gerrymander better than Democrats – or at least, have more gerrymandered states than Democrats, likely due to their heavy levels of victories back in 2010 (see: 2010 Election Results) – and it shows. &amp;amp; 2. Vote share and seat share does align in some states, showcasing that our system is not entirely screwed up.&lt;/p&gt;
&lt;p&gt;Altogether, our political system in the House of Representatives needs work to ensure fair representation. However, based on how engrained gerrymandering is in American political culture – I am far from hopeful.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #1</title>
      <link>https://example.com/post/blog-post-1/</link>
      <pubDate>Tue, 13 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-1/</guid>
      <description>


&lt;p&gt;Question/Blog Extension we are going to be going through:
Heterogenous Predictive Power of the Economy.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Does the effect of the economy vary when we consider popular vote versus seat share as our outcome (dependent) variable?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Does the predictive power of economy change across time? If so, why?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To begin, this blog post will be dealing with data sets that have been filtered and combined through R. This blog post will be utilizing GDP Quarter 7 data from the midterm years 1962-2018. By my own discretion, I have removed the presidential election years, as the data set does not treat the “president_party” variable as the party going into the election, but rather the victor of the presidential election. Consequently, I felt it would be most beneficial if that was taken out of the equation for this blog post. Additionally, as this class is focused on the 2022 midterms, I hoped to utilize the midterm-only data to guage a better understanding of midterms.&lt;/p&gt;
&lt;p&gt;To sort our data, I combined economic data and House of Representatives election data. In addition, we filtered, then mutated the data to create two new variables within our blog: pres_party_seat_share and pres_party_vote_share. The seat share was defined as the # of seats for the president’s party divided by 435 (total # of seats in the U.S. House). This also explains the reasoning behind the year selection, beginning in 1960, as that was the first year in history with 435 House seats (following Hawaii &amp;amp; Alaska’s addition to the United States).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
With this data, we first created a scatterplot based on the “Quarter 7 GDP Growth” and “President’s Party Seat Share.” GDP growth in Quarter 7 was chosen as the most recent quarter leading into an election. The expectation was that a recent bump (or lackthereof) in the economy would either benefit/hinder the president’s party in seat share (similar to what we read in Healy and Lenz || &amp;amp; Achens). To test, we formed the scatterplot while placing a linear regression model line on the graph itself.&lt;/p&gt;
&lt;p&gt;My personal expectations were that GDP growth would result in president’s party seat share being nearly 50% or above. Unfortunately, the model did not find the GDP growth and party seat share to follow my expectations. There were numerous instances where the president’s party’s seat share was below 50%, despite the GDP growth being around 1% or even more. Whenever the GDP growth was negative, the president’s party never received above 50% of the seat share.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
Then, we moved on to see if the president’s party’s vote share was more reflective than seat share, as described by the blog extension. When we ran the model, we did not find it to be particularly accurate, but there were instances (similar to seat share) of accuracy. Again, the economy and seat share relationship did not match expectations to the extent that was originally thought. Though similar to the president’s party seat share, it did reveal that there was not one instance where a president’s party won the majority of the popular vote when GDP growth was negative. This made sense.&lt;/p&gt;
&lt;p&gt;Then, we aimed to calculate the actual linear regression number on the GDP growth pct as it relates to president’s party vote vote share &amp;amp; president’s party seat share.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
To begin, we looked at the relationship at a quantified relationship between pres_party_vote_share and GDP_growth_pct. We found the calculation to be 3.65, thus indicating that for every 1% increase in GDP, we can expect the president’s party vote share to increase by 3.65%. I do think this number could be defending in traditional election circumstances, but the 15 midterm years we are utilizing for analysis make me somewhat uncertain about this. If I had the ability, I would use data from past midterms well beyond 1962, given that I had additional time &amp;amp; data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;
We then ran the other calculation. Our calculations found a value of 8.174 between a lm calculation of pres_party_seat_share and GDP_growth_pct. This means that for every 1% increase in GDP, we could expect an 8.17% increase in pres party’s seat share. However, I do not buy this number. This is such a large number that simply does not make much sense in the modern political world. A 1% increase will likely not result in an 8% increase in future elections, especially midterm ones with many more factors than the economy. While an interesting finding, I do not know if I trust it entirely. Similar to above, I would also wish to explore this with additional time &amp;amp; resources.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;672&#34; /&gt;
The second part of this blog extension is to see if there is a change in accuracy over time in these elections. Plainly put: there does not appear to be.&lt;/p&gt;
&lt;p&gt;To determine this, we utilized a plot that mapped both a predicted model (based on our data) and the actual model. The party vote share based on actual results vs predicted results did find some spot-on accuracies in the elections of: 1974, 1982, 1990, and 2008. There were also some close calls, but on the overall, it was not nearly as predicitive as it could’ve been. Given the range of accuracy/innacuracies across the time frame, I believe that there is not a significant difference overtime.&lt;/p&gt;
&lt;p&gt;When applying this to seat share, predicted vs actual, there were spot on predictions but also many that missed the mark. Generally, there were not many points of consistent accuracy or consistent inaccuracies, as accuracy was a variety across the board.&lt;/p&gt;
&lt;p&gt;Main takeaways:
GDP growth does not seem to be the most predicitve/accurate indicator for a president’s seat growth or vote share
“It’s the economy, stupid.” may not be as true as we think
Time did not help the accuracy/predictive ability of our models&lt;/p&gt;
&lt;p&gt;Sources:
1. Achen and Bartels (2017)
2. Healy and Lenz (2014)
3. I did not use Wright as there was no unemployment calculations.&lt;/p&gt;
&lt;p&gt;Data being used:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;GDP growth (national): 1947-2022 (US Bureau of Economic Analysis, Department of Commerce)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Real disposable income (national): 1959-2022 (US Bureau of Economic Analysis)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inflation – CPI (national): 1947-2022 (US Bureau of Labor Statistics, Department of Labor)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unemployment (national): 1948-2022 (US Bureau of Labor Statistics)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unemployment (state): 1976-2022 (US Bureau of Labor Statistics)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
