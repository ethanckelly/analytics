<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Academic</title>
    <link>https://example.com/post/</link>
      <atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 07 Dec 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://example.com/post/</link>
    </image>
    
    <item>
      <title>Post-Election Campaign Narrative</title>
      <link>https://example.com/post/post-election-campaign-narrative/</link>
      <pubDate>Wed, 07 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/post-election-campaign-narrative/</guid>
      <description>


&lt;p&gt;Post-Election Campaign Narrative&lt;/p&gt;
&lt;p&gt;Welcome to my post-election campaign narrative blog post! In this blog post, we will be exploring Maryland’s 6th Congressional District. After intense judicial drama dealing with the legislative district boundaries, Maryland’s 6th district became instantly one of the most competitive in the country.&lt;/p&gt;
&lt;p&gt;Let’s move into understanding the background of the 6th district!&lt;/p&gt;
&lt;p&gt;== Background ==&lt;/p&gt;
&lt;p&gt;To begin, the 6th district is a relatively new one. It was birthed out of the 2020 congressional redistricting cycle &amp;amp; serves to be as the most important district within the state of Maryland. However, to understand the competitive nature of this district &amp;amp; the overall election results, it is important to understand how this district came to be so competitive.&lt;/p&gt;
&lt;p&gt;After Democrats expanded their supermajority in the State Legislature, the Maryland Democrats passed a congressional map that &lt;em&gt;intitally&lt;/em&gt; saved the incumbent, David Trone, from any level of competitiveness for the next decade. According to FiveThirtyEight, a reputable source of political information, the 6th district was intended to be D+12 (the previous district was D+16). However, a Circuit Court Judge named Lynne Battaglia struck down the map, calling it “unconstitutional, and [that it] subeverts the will of those governed.”&lt;/p&gt;
&lt;p&gt;Consequently, the map had to be redrawn – fairly this time. Upon completion of the new map, Governor Larry Hogan signed it into law, and the district then held a partisan lean of R+1. From this moment onward, Maryland’s 6th district was on the GOP’s radar. With high expectations for the midterms, they thought this would be a prime opportunity for a pickup for Republicans.&lt;/p&gt;
&lt;p&gt;Before we get more into election forecasting, results, and analysis — we should know more about the 6th. In terms of demographics, of the estimated 790,000 residents, the district is majority-white, with about 56% of constituents identifying as White Americans. An additional 14% identify as Black, 16% as Hispanic, and 12% as Asian; about 3% remains two + more races (or other). This district is diverse – but is dominated by urbanites (+suburbanites, as there is no classifier for this), with 84% of the district being referred to as “urban” and 16% referred to as “rural.” In terms of median household income, the 6th district’s is $86,077, higher than the national median of $70,784. About 91% of the district has a high school diploma, with 43% having additionally graduated college.
Now that we’ve talked demographics, let’s move directly into geography, candidates, and electoral history. In terms of geography, Maryland’s 6th district is one of Maryland’s largest. It contains semi-large cities in Maryland, alongside some extremely large plots of farmland. It is a combination of urban, suburban, and rural areas – with most of the land coming from urban + suburban areas. It is connected to West Virginia and Virginia, while also directly bordering Pennsylvania on the top.&lt;/p&gt;
&lt;p&gt;As for the candidates, incumbent Democrat David Trone ran for re-election in this district. He was first elected in 2018 during the blue-wave midterm, after Representative John Delaney announced his bid for President of the United States in 2017. Trone’s first time running for Congress was in 2016 (for an entirely different district), where he rose to prominence for spending $13 million of his own money on the race. However, he lost to John Delaney, but won the seat back 2 years later. He is a former winemaker &amp;amp; business, who’s stake in the district was mostly his incumbency. As a candidate, Trone was not regarded as extremely powerful, but was not thought of as “weak” or “lackluster.”&lt;/p&gt;
&lt;p&gt;The Republican nominee, Neil Parrott, ran against Trone in the 2020 election. He was a recognized name who faced a well-known Republican opponent in the primary. His opponent, Matthew Foldi, was endorsed by Larry Hogan, Donald Trump Jr., Kevin McCarthy, and many more. However, Foldi ended up losing by over 50% to Neil Parrott – mostly due to Parrott’s previous candidacy &amp;amp; name recognition. Parrott fed into Donald Trump’s 2020 election lies &amp;amp; was involved in the “observation of ballot counting” in Pennslyvania.&lt;/p&gt;
&lt;p&gt;Now, let’s move into electoral history. Since we are working with a brand new congressional district, the past voting history is a bit difficult to use as a factor in understanding the district. However, we do have PVI’s based on how this new district would have voted in the past. Applying the new boundaries to the 2020 presidential election, Joe Biden won the 6th district by single digits (under 5%). Estimates have it around Biden +1-3%, quite insignificant from the former district’s 15%+ margin for President Biden. To aide in the understanding of the district, FiveThirtyEight rated it as R+1 &amp;amp; the Cook PVI has it as D+2.&lt;/p&gt;
&lt;p&gt;Finally, as my forecast was rooted in expert predictions, we will be looking at expert forecasts for this election. My 3 main forecasters for my model came from the Cook Political Report, Inside Elections, and Larry Sabato’s Crystal Ball. Their rating were as follows (in respective order): Likely Democrat, Likely Democrat, and Lean Democrat. Altogether, they average to a semi-significant Democratic victory.&lt;/p&gt;
&lt;p&gt;Since we know a lot about the district, let’s move directly into the results vs. the forecast.&lt;/p&gt;
&lt;p&gt;== Accuracy of Forecasts ==&lt;/p&gt;
&lt;p&gt;My forecast was rooted in the predictions of expert forecasters. As previously mentioned, I worked with Larry Sabato’s Crystal Ball, Inside Elections, and the Cook Political Report. My forecast used accuracy of the previous forecasts from 2012-2020 in order to create a model to predict each district in 2022. In this case, my model predicted that incumbent David Trone would win 63.7% of the vote in the 2022 election. The final result ended up being about 9 points worse for Democrats, with Trone winning 54.8% of the vote.&lt;/p&gt;
&lt;p&gt;Most pundits expected David Trone to win his race, as nearly all of the forecast websites and companies predicted a Democratic hold. The closest it was expected to be was a “Toss-Up” declaration. FiveThirtyEight’s 2022 House Model predicted David Trone to win about 52% of the vote, giving him a 71% chance of winning. FiveThirtyEight uses expert forecasters in a similar fashion to my model — expect they add it into a number of other factors.&lt;/p&gt;
&lt;p&gt;Reflecting on my prediction, I significantly overestimated Democratic support. Regardless of the year, the 6th district likely will not be going to a Democrat with 63%. David Trone’s result was surprising, in terms of margin at least, and while my model did predict a significant margin, it was still off.&lt;/p&gt;
&lt;p&gt;Altogether, the model I put together was accurate in the overall winner &amp;amp; accurate in suggesting a larger-than-average victory. However, there was consistent overestimation for Democrats (across the country, not just here) in my model. My final prediction was 220-215, Democrats winning the majority. My final model ended up being wrong (in terms of predicted party victory) by 17 seats in total, mostly inaccurate calls for Democrats.&lt;/p&gt;
&lt;p&gt;Now that we’ve seen the accuracy, or lack thereof, of my model, it is time to move into the narrative of the campaign.&lt;/p&gt;
&lt;p&gt;== Campaign Narrative ==&lt;/p&gt;
&lt;p&gt;This campaign, like many others, was nationalized to an extremely high extent. Both candidates were associating each other with top names, such as Donald Trump and Joe Biden. Trone and Parrott aimed to make this race beyond themselves — largely in part that neither of them were super well-received or admired.&lt;/p&gt;
&lt;p&gt;On the side of the David Trone, his campaign focused on a multitude of issue leading into the summer of 2022. Whether it was focused on COVID-19 recovery, mental health, etc., Trone was the stereotypical Democrat aiming to highlight their victories over the past 2 years. However, when Roe V. Wade was overturned in June of 2022, Trone’s campaign shifted primarily to the issue of abortion.&lt;/p&gt;
&lt;p&gt;In context, Maryland is an extremely pro-choice state. Opinions on being pro-abortion-rights are significantly high, being significantly higher than Democratic Party vote share on the statewide level. As a result, a competitive, R+1 district, such as the 6th, will be likely in favor of abortion access by a margin of 60-40. Point being: Trone’s campaign shifted to an issue they knew they would be the Republicans on.&lt;/p&gt;
&lt;p&gt;== Campaign + Media Narrative ==&lt;/p&gt;
&lt;p&gt;The media’s narrative was pretty similar to that on the national level. This district was seen as one of the bigger victories (should it had happened) for the GOP — as it would be flipped “deep blue Maryland.” The narrative was that the voters in the 6th were pushing back on President Biden &amp;amp; wished to express their discontent with the Democratic Agenda.&lt;/p&gt;
&lt;p&gt;The presence of this race in local media was pretty significant — outmatching any other congressional district in the state. The media covered Trone’s focus on abortion, highlighting some of the comments made by his opponent. As the country turned to abortion, so did the Maryland press. Additionally, the coverage was hyping up the competitiveness of this district, likely to an over exaggerated extent. The district was going to be close, but it was not a nail-biter nor was it going to determine the balance of power in the House.&lt;/p&gt;
&lt;p&gt;The Bethesda, Maryland magazine: the Bethesda Beat, highlighted the competitive nature of the race right before the election. In a late-October article, they claimed the race was “heating up in the final days,” referencing insider polls that showed the race within a few points. They continued this article with a showcase of some of Parrott’s ads against Trone, which could very well summarize the GOP’s main points by the end of the race. The advertisement was as follows: “Fire far-left David Trone… We can’t afford another two years of the Biden/Pelosi/Trone agenda.” Essentially — tying Trone to Pelosi &amp;amp; Biden was the biggest attack the Republicans had. By this point, one can assume that the race was moving away from the GOP if THIS was their hard-hitter.&lt;/p&gt;
&lt;p&gt;Additionally, local drew significant juxtapositions between Trone and Parrott. Parrott told the local media that he would be “definitely interested in joining [the House Freedom Caucus],” a caucus responsible for Marjorie Taylor Greene, Lauren Boebert, and 38 other far-right Republicans in the House. This comment stuck with the media &amp;amp; the voters. Non-local sites such as OpenSecrets, the Diamondback, and the Washington Post dove deeper into policy differences between the candidates. Whether on issues of social security, military spending, healthcare, etc. — this was not the concern of voters &amp;amp; thus barely covered by the media.&lt;/p&gt;
&lt;p&gt;From the side of Neil Parrott, the media covered him with heavy scrutiny. His comments about election denial &amp;amp; the insurrection were covered quite heavily. Additionally, he made a comment that people with HIV should not be able to get a tattoo, and another comment about banning abortion in every case. These comments Parrott made resulted in extensive coverage of his gaffes and mistakes. Unlike Trone, Parrott is extremely outspoken on social issues that the 6th district does not align with him on. As a result, he likely lost voters on the key issues that Trone highlighted.&lt;/p&gt;
&lt;p&gt;In terms of endorsements after the primary elections, they typically do not hold much weight. Both sides of the aisle send in big names to endorse their lesser-known candidates. However, there was little media coverage of Parrott’s Republican endorsements.. because he had so few. After the primary, the majority of Republicans who endorsed Matthew Foldi refused to endorse Parrott in the general election. Whether through ignorance or explicitly stating as such, top Republicans such as Larry Hogan did not back Parrott in the general.&lt;/p&gt;
&lt;p&gt;His comments on abortion, the election, and much more likely shifted voters away from him. While I do not personally think voters viewed Trone as an aweinspirational candidate, he was certainly higher in “candidate quality” than Parrott. He aligned with voters on more issues and he knew how to play the political game. Unfortunately for Parrott, it was evident that Trone was the better candidate — and it came across through the reporting of the media. Essentially, Parrott dug his own grave (with help of national Republicans &amp;amp; the United States Supreme Court).&lt;/p&gt;
&lt;p&gt;In specifics, Parrott made a number of missteps that can be quantified into points below:
His candidacy was rooted in tying Trone to Biden – despite the expectations for 2022, the year ended up being a lot more about candidate quality than we thought. While President Biden’s shortcomings were centerfocused in some regard, they were not the main focus of the election &amp;amp; Parrott failed to recognize this.
He treated this race as a Trump-like figure – in his case, Parrott very much was an extreme Republican given the sentiment across the district. Rather than be a swing-district Republican, he was quite more conservative than other Republicans who did phenomenally here. Governor Larry Hogan, a Republican, won MD-6 by over 10 points – yet Parrott lost here by 10 points. Why? GOP candidate quality &amp;amp; stances.
He gave the media too much to work with – going on the record with points that can be viewed as anti-Women, anti-LGBTQ, etc. are things that a candidate should avoid. For Parrott, he was loud &amp;amp; proud and did not avoid the press with these topics. He failed to pivot &amp;amp; shift focus correctly &amp;amp; the voters knew this.&lt;/p&gt;
&lt;p&gt;The candidates did a lot in terms of campaigning. Both utilized social media as a major fundraising tool, while they crowded the airwaves with TV ads day-after-day. There was extensive ground game by the Maryland Democrats &amp;amp; Republicans, as all eyes were focused on this race. Without a competitive race in the state, it was all hands on deck. Even some Virginia Democrats came up to canvass for David Trone. The point is: this campaign was the hottest issue in all of Maryland and it showed.&lt;/p&gt;
&lt;p&gt;== What does Election Analytics tell us? ==&lt;/p&gt;
&lt;p&gt;According to Brown (2014), incumbency is a factor that Trone likely did not ride to re-election. With the economy moving in an unsatisfactory direction, Trone likely should have been punished for this. Biden’ s inability to do major initiatives related to inflation &amp;amp; other aspects of the economy likely hindered Trone’s victory. However, in relation to incumbency, voters do not always have a preference on that basis alone. A lot of other factors are thrown into it, but I do not know if I entirely agree with the literature, however it is clear (in reflection) that Trone likely won due to many other factors.&lt;/p&gt;
&lt;p&gt;However, to the point of other factors influencing the race, Trone was still associated with President Biden. According to FiveThirtyEight, he voted with President Biden 100% of the time since getting into office. As mentioned in Canes-Wrote et al. (2020), there are electoral ramifications for voting with your party. Especially in a swing district, vote share has been found to decrease as an incumbent’s support for their own party increases. However, while Trone did not win by 20 (as he did in 2018), he severely outperformed the expectations for this district.&lt;/p&gt;
&lt;p&gt;As we look to reflect upon this race, it is important to look at literature that deals with reflecting on models &amp;amp; accuracy of predictions. We know from Vavreck (2009) that candidates that deal with economic fallback (aka Trone) must shift the race to a focus on issues beyond the economy. Ultimately, Trone did this successfully. As acknowledged by Vavreck, candidates do not always have the ability to do this. Looking at candidates in 2010 &amp;amp; 2014 – it was difficult to separate the economy from the voters. However, in 2022, the Supreme Court’s intervention in a woman’s right to chose resulted in candidates, like Trone, the ability and agency to shift the focus on abortion (and other issues impacted by the SCOTUS).&lt;/p&gt;
&lt;p&gt;== Conclusion ==&lt;/p&gt;
&lt;p&gt;In conclusion, the Maryland 6th Congressional District race was more competitive than it had been in nearly a decade. The district, redrawn out of a fresh redistributing cycle, was the focus of media outlets across Maryland and the nation. Two candidates ran: incumbent Democrat David Trone &amp;amp; State Senator Neil Parrott. Parrott ran against Trone in the past, but faced new scandals and challenges as he headed into this election. Trone, on the other hand, shifted his campaign focus to the issue of abortion — a move inspired by the Supreme Court’s decision to overturn Roe V Wade.&lt;/p&gt;
&lt;p&gt;My forecast was based on the 3 main sources: Cook, Inside, and the Crystal Ball. Together, my model predicted Democrats winning the 6th district with 63% of the vote. They ended up winning 54% — an overestimation on my end of 9%. This district is a Biden +1-3% district &amp;amp; has a 538 PVI of R+1. Candidate quality played a major role in the Democratic Party’s victory — despite neither candidate being extremely strong, Parrott’s weakness was very apparent.&lt;/p&gt;
&lt;p&gt;Thank you for taking the time to read this post! Following this race over the Fall Semester was very fun :)&lt;/p&gt;
&lt;p&gt;Till we meet again,
Ethan &amp;lt;3&lt;/p&gt;
&lt;p&gt;Direct Bibliography (many other sources went into research over the semester):&lt;/p&gt;
&lt;p&gt;Brown, Adam R. “Voters Don’t Care Much About Incumbency.” Journal of Experimental Political Science, vol. 1, no. 2, 2014, pp. 132–43, &lt;a href=&#34;https://doi.org/10.1017/xps.2014.6&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/xps.2014.6&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Canes-Wrone, Brady, D. W., &amp;amp; Cogan, J. F. (2002). Out of Step, Out of Office: Electoral Accountability and House Members’ Voting. The American Political Science Review, 96(1), 127–140. &lt;a href=&#34;https://doi.org/10.1017/S0003055402004276&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1017/S0003055402004276&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vavreck, Lynn, and Lynn Vavreck. “The Message Matters.” 2009. 232 Pp, STU - Student edition, Princeton University Press, 2009, pp. 1–205, &lt;a href=&#34;https://doi.org/10.1515/9781400830480&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1515/9781400830480&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Peck, Louis. “Trone vs. Parrott Rematch Heats up in Final Days before Nov. 8 Election.” Bethesda Magazine &amp;amp; Bethesda Beat, Bethesda Magazine &amp;amp; Bethesda Beat, 27 Oct. 2022, bethesdamagazine.com/2022/10/27/trone-vs-parrott-rematch-heats-up-in-final-days-before-nov-8-election/. Accessed 17 Dec. 2022. ‌&lt;/p&gt;
&lt;p&gt;Board, Editorial. “The Post Endorses Trone and Parrott in the Maryland 6th District Primaries.” Washington Post, The Washington Post, 10 July 2022, www.washingtonpost.com/opinions/2022/07/10/maryland-6th-district-primary-endorsement-2022/. Accessed 17 Dec. 2022. ‌&lt;/p&gt;
&lt;p&gt;“Redistricting Brings New Competition to Maryland’s 6th Congressional District.” The Diamondback, 19 Oct. 2022, dbknews.com/2022/10/19/district-6-maryland-congressional-election-redistricting/. Accessed 17 Dec. 2022. ‌&lt;/p&gt;
&lt;p&gt;Siemons, Jorja. “GOP Lead Fundraiser Neil Parrott Wins Maryland Primary in Competitive District.” OpenSecrets News, 22 July 2022, www.opensecrets.org/news/2022/07/leading-gop-fundraiser-neil-parrott-wins-primary-in-marylands-6th-district/. Accessed 17 Dec. 2022. ‌&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Post-Election Reflection on Model</title>
      <link>https://example.com/post/post-election-reflection-on-model/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/post-election-reflection-on-model/</guid>
      <description>


&lt;p&gt;== Post-Election Reflection on Model ==&lt;/p&gt;
&lt;p&gt;Hello everyone! After such an incredible campaign and midterm season, we are finally, finally over. However, our discussion of the 2022 midterms is far from over! In this blog post, we will be discussing the accuracy of my model &amp;amp; my reflection on it. The 2022 midterms were quite exciting – so let’s get into it!&lt;/p&gt;
&lt;p&gt;To provide context, the idea for this model was birthed out of a rotation of predictive models based on various factors; whether GDP growth, generic ballot, incumbency, expert forecasts, etc. However, one model in particular jumped out to me: expert forecasts. A model based on expert forecasts enticed me, as it combined all of the factors we aimed to compute and utilize in our forecast, simplifying it into terms of Lean, Likely, and Safe characterizations. I felt it would be fascinating to predict the midterms based on expert forecasts &amp;amp; it absolutely was. Let’s look at it!&lt;/p&gt;
&lt;p&gt;== Recap of my model ==&lt;/p&gt;
&lt;p&gt;My model utilized forecasts from 3 main political companies: the Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. These election forecast companies have been around for years &amp;amp; have been predicting congressional, presidential, and gubernatorial elections since the beginning of the 21st Century. The reasoning behind choosing these factors were due to the fact that these companies are some of the most frontward facing &amp;amp; they provide more transparency about their decisions behind the models. Ultimately, I felt these would be the most helpful when predicting the midterm elections.&lt;/p&gt;
&lt;p&gt;With these 3, each rating provided by the company would be turned into a respective number. These numbers were based on a scale of 1-7, with 1 being the most Republican &amp;amp; 7 being the most Democratic.&lt;/p&gt;
&lt;p&gt;Here it is:&lt;/p&gt;
&lt;p&gt;1 - Safe Democratic victory 2 - Likely Democratic victory 3 - Lean Democratic victory 4 - Pure toss-up 5 - Lean Republican victory 6 - Likely Republican victory 7 - Safe Republican victory&lt;/p&gt;
&lt;p&gt;The 3 separate ratings were averaged &amp;amp; distributed back across the 2022 districts.&lt;/p&gt;
&lt;p&gt;The model’s creation, in addition, was created in a similar way. These ratings for each 435 districts were averaged in elections from 2012-2020, with a new variable added in a column: Democratic Party vote share. Essentially, we ran a regression to find the connection between ratings &amp;amp; the Democratic Party’s performance in past elections – we then used that model to predict 2022 based on historical accuracy.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/post-election-reflection-on-model/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our predicted result for the 2022 midterms resulted in an expected Democratic Majority of 220 seats, to the Republican Party’s 215. This would be a loss of 2 seats for Democrats, and a gain of 2 for Republicans. This result was, plainly put, shocking. Democrats have been the underdogs in this race since November 7th, 2020, when President Joe Biden was the predicted winner of the 2020 election. Democrats held the slimmest majority in the 21st Century, yet ultimately were being predicted to win the race by my model. You can see it visualized below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        group Predicted_Results
## 1 Republican               215
## 2   Democrat               220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/post-election-reflection-on-model/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When I saw the results, I was quite shocked. It made no sense. This model, in my eyes, was not going to be accurate. However, let’s look at the actual results, as I was even further surprised.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        group Current_House_Composition
## 1 Republican                       222
## 2   Democrat                       213&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/post-election-reflection-on-model/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The results of the 2022 midterms (assuming all those leading in races end up winning) will be a mirrored flip of the 2020 House election results: Republicans at 222, and Democrats at 213. As an aside, this is exactly what happened from 2016 - 2020 in the presidential election in the electoral college (just thought this was cool).&lt;/p&gt;
&lt;p&gt;In terms of individual races, the model based on expert forecasts ended up inaccurately predicting just 4% of House races (17 races). The model ended up correctly predicting 418 out of 435 districts ~ about 96.1% accuracy. Plainly put – the model itself was quite accurate and ended up only being off of the actual results by 17 individual races, but on the overall net of just 8 seats!&lt;/p&gt;
&lt;p&gt;To gauge a further level of accuracy, we will be exploring the Root Mean Square Error of the prediction vs. the observation (the result).The RMSE was calculcated by figuring out the difference between predicted Democratic Party vote share and actual Democratic Party vote share. This led us to the RMSE os 0.1202, which I rounded to 0.12. This is not that bad – this is not what I expected when I found out I was one of TWO people in the class who predicted a Democratic majority. Though the 12% error, on the topic of accuracy, I’d argue that my model was quite accurate, even if I did not think it would be on election day.&lt;/p&gt;
&lt;p&gt;Some interesting things about accuracy with this forecast (worth mentioning… at least):
1. All of the inaccuracies occured in states that are consider “East Coast (including PA)” or “West Coast.” None of “Middle America” was predicted wrong by these forecasts.
2. A large sum of the inaccuracies came from very populous states: New York + California
3. The model had only a 55% success rate in predicting the house races in Virginia (the least correct state… by far)
4. Contrary to what forecasting sites, such as FiveThirtyEight and The Economist, said, the model was very accurate in some extremely competitive races (in NC, IA, AZ, NV, etc.)
5. About equal number of districts were overestimated for Democrats &amp;amp; Republicans&lt;/p&gt;
&lt;p&gt;Now that we’ve talked accuracy, let’s move onto what could have impacted the model’s accuracy!&lt;/p&gt;
&lt;p&gt;== What went wrong, how to check, and what to improve ==&lt;/p&gt;
&lt;p&gt;My model was not perfect. Though I wish it was, there are some parts of the model (also dealing with the underlying variables that contributed the expert forecasts) that could be weighing down the accuracy of the model.&lt;/p&gt;
&lt;p&gt;One source of error could be the fact the model was only utilizing Cook, Sabato, and Inside Election. This could have limited the predictive ability of experts across the board, as we failed to include other pundits and their ratings (even some notable ones: FiveThirtyEight, The Economist, RealClearPolitics, etc.). To test if this was one of the determining reasons as to why the model was inaccurate, we could create another model with more forecasters &amp;amp; compare predicted seat share vs. prior-predicted seat share. We can see if the RMSE is significantly different and/or if the seat share is more accurate by %. These quantitative tests would provide us clarity as to whether the beliefs of the masses are more accurate than the big 3.&lt;/p&gt;
&lt;p&gt;Another source of error could be that our model was predicting based on only 5 years of data to compare. In using 2012-2020, we had the luxury of working with the same congressional districts in a more-modern timeframe of the 21st Century. It provided us similar conditions that we could expect for 2022, but it also could have been to our detriment. By using only 5 years, it is very possible that these forecasts were incorrect in previous years, thus making it incorrect for 2022. Additionally, we found that the model had a left-ward bias – this is something that could be a product of working with such a few years (especially when 2016 &amp;amp; 2020 threw off so many political pundits). If we want to apply a quantitative test, we could re-do the linear regression model &amp;amp; create a model using singular years. An example would be a 2022 midterm model based on 2018 accuracy. This would allow us to compare to see which was the most D-leaning, R-leaning, etc! After that, we can see which year ended up being the most accurate.&lt;/p&gt;
&lt;p&gt;Another major factor that likely led to inaccuracies in this cycle is redistricting. This election cycle is very different from the past few that have been utilized in our model. This one is brand new – new districts, new candidates, new environment. Consequently, it is very possible that pundits are not going to be as accurate in this year’s prediction, as they may be in 2024, 2026, etc. when the new boundaries have more data behind them. While this would not be a perfect way to approach testing redistricting as something that can be fixed, we could compare 2012 accuracy vs 2014, or (in the future) 2022 vs 2024. Potentially, more data behind the new districts could benefit the forecasting process &amp;amp; thus future models similar to mine. The second-to-last error I’d mention, briefly, is human error. There is a possibility that this model had data that was incorrectly input/compiled, and thus could alter the outcome of the model.&lt;/p&gt;
&lt;p&gt;Ending on this note, one major factor we always should consider when reflecting on 2022 models is that 2022 was a bad year for polling, turnout modeling, etc. There were significant levels of inaccuracies in district-by-district polls this cycle, on top of inaccuracies in turnout models. Altogether, this year was not perfect &amp;amp; the data that these expert forecasters were using was also not perfect. While there is no quantitative test to see if the “incorrectness” of an election year has impacted the model, it is something to keep in mind. The data the experts were using was thrown off by the Roe v Wade effect, shifting approvals for Republicans, and important top-ballot races that were more dominating than the congressional ones.&lt;/p&gt;
&lt;p&gt;Now, let’s talk about…&lt;/p&gt;
&lt;p&gt;== What I’d do differently ==&lt;/p&gt;
&lt;p&gt;If given the opportunity to expand on my model with more time &amp;amp; resources, I would approach certain aspects of it differently.&lt;/p&gt;
&lt;p&gt;To begin, I would move to add in additional forecasts from what I currently have. I would like to add in 5-10 more networks/companies to help increase accuracy. The problem with just 3 meant that the room for error was more significant. Additionally, since we were averaging all 3 ratings, they were not always in close proximity. Some ratings of the same district were Likely R while others had a Toss-Up characterization. Issues such as that could skew the results &amp;amp; significantly throw off the average, unlike a model with significantly more forecasts.&lt;/p&gt;
&lt;p&gt;Next, I would source for more historical data. Time permitting, I would absolutely scrape and look back at historical ratings well beyond 2012. Many forecasters have been predicting elections for decades &amp;amp; the model would stand to gain by having more history added into it. This could help ensure that there is no recency bias or recent inaccuracies significantly altering our results/expectations for both parties.&lt;/p&gt;
&lt;p&gt;Finally, I would aim to adjust for prior mistakes by these forecasters. Taking into account data on a year-by-year basis, I would focus on recognizing D-leaning and R-leaning years. This would mean adjusting for inherent bias in the ratings once we have compiled the results (easily done for years past), and apply a bias-correction to the model itself, hopefully avoiding any consistent, prevalent bias that we recognize.&lt;/p&gt;
&lt;p&gt;== Conclusion ==&lt;/p&gt;
&lt;p&gt;Overall, the model of expert forecasts proved to be more accurate than I expected. Though the model was off by about 7 seats (net), this is closer than other models were. Some pundits who are paid tens of thousands of dollars predicted worse than my model – so ultimately, I am happy with it. While there is much to improve upon in the future, I truly enjoyed working with the model of the past 2 weeks &amp;amp; reflecting on the results. If there’s one thing this midterm proved: anything is possible.&lt;/p&gt;
&lt;p&gt;Thank you for taking the time to read my reflection :)&lt;/p&gt;
&lt;p&gt;Peace out!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Forecast of the 2022 Midterm Elections</title>
      <link>https://example.com/post/forecast-of-the-2022-midterm-elections/</link>
      <pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/forecast-of-the-2022-midterm-elections/</guid>
      <description>


&lt;div id=&#34;finally-the-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Finally, the prediction&lt;/h2&gt;
&lt;p&gt;Hello everyone! My name is Ethan Kelly &amp;amp; as of writing this piece, I am a sophomore living in Leverett House, studying Government &amp;amp; Computer Science. In this final blog post, we will be exploring the 2022 midterm elections &amp;amp; my model for the congressional elections. This has been a product of an entire semester of studying various impacts on the outcomes of elections &amp;amp; I am excited to finalize my prediction just one day before the elections.&lt;/p&gt;
&lt;p&gt;To begin, this model is based on forecast ratings from 3 major political forecast sources: The Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. All of these forecasters take into account various variables when it comes down to their predictions. Whether this be inflation, presidential approval, generic ballot, previous voting history, turnout expectations, GDP growth, among many, many others, they formulate their predictions into a system of ratings. This system works from Safe Democrat to Safe Republican. My model translates these ratings into a 7 point scale, which can be broken down in the following translation:&lt;/p&gt;
&lt;p&gt;1 - Safe Democratic victory
2 - Likely Democratic victory
3 - Lean Democratic victory
4 - Pure toss-up
5 - Lean Republican victory
6 - Likely Republican victory
7 - Safe Republican victory&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One exception to this 7 point scale was Inside Election’s usage of Tilt characterizations (to which Tilt Democratic was 3.5 &amp;amp; Tilt Republican was 4.5)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The expert ratings utilized came from the past decade, 2012-2020. This was specifically chosen given the consistency of the congressional districts, while honoring a more-recent trend in hyper-partisanship across the nation. Additionally, these forecasters have been much more outward facing in recent time, rather than in a historical context. Essentially – the data only goes so far back. I acquired this data through the primary method of scraping the websites of the 3 major forecasters. To do this, the data required research across the Wayback machine (a website time traveler), though I also acquired data from a senior analyst at Larry Sabato’s Crystal Ball. To get the data necessary, I contact J. Miles Coleman via Twitter &amp;amp; received the Crystal Ball data from 2012-2020.&lt;/p&gt;
&lt;p&gt;The procedure for this model came in the dataset, where the average was calculated of all of the forecast ratings &amp;amp; used as a general “average.” This average allows us to explore the combination of ratings, additionally avoiding toss-ups, as no district had all 3 ratings as “tossups.”&lt;/p&gt;
&lt;p&gt;To see how accurate our model is, we are going to find the correlation between the expert ratings &amp;amp; Democratic party vote share. The decision to make this my model was rooted in the weeks of forecasts based on different outcomes in past blog posts. During one of the weeks, my partner (in class) Julia &amp;amp; I made a joint presentation on the risk of using expert predictions in a model. We talked about the risk of overfitting, as one may be taking into account a multitude of factors as they make a model that includes expert forecasts. Essentially, if Cook decides to use GDP growth in their forecast for house districts, then I make a model including both GDP growth &amp;amp; expert forecasts, I am account for a variable twice over.&lt;/p&gt;
&lt;p&gt;Additionally, much of my work in political analysis is understanding the accuracy of these expert forecasters; organizations that make hundreds of thousands of dollars should have a pretty accurate prediction, right? Well, this is a question I am excited to find the answer to after tomorrow evening (or maybe Election Week 2.0)!&lt;/p&gt;
&lt;p&gt;To begin in this forecast, we will be exploring the linear regression model between the past years plotted onto a graph.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/forecast-of-the-2022-midterm-elections/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/forecast-of-the-2022-midterm-elections/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As seen above, there is a clear correlation between the Democratic Party’s vote share &amp;amp; expert ratings across districts. The data points in that plot are a combination of the 2012-2020 congressional elections. To make this correlation most clear, we find the R-squared value to be 0.697. This shows a semi-strong correlation between the two variables, thus indicating that there is a signficant level of accuracy between the forecasts and the actual results.&lt;/p&gt;
&lt;p&gt;There is only one coefficient, besides the constant, in this linear regression model – average rating. The summary of the model shows that as average rating goes up by 1, the expected Democratic Party voteshare decreases by 7%. This means, the closer we get to a Republican victory, the less Democrats end up getting in the final results. Makes sense!&lt;/p&gt;
&lt;p&gt;Let’s move on to see what the predictions are saying across all of these forecasts.&lt;/p&gt;
&lt;p&gt;== Predictions by Individual Expert Forecast ==&lt;/p&gt;
&lt;p&gt;These models are all created by training an expert forecast model with data from 2012-2020. As mentioned previously, we have combined all of the expert ratings across historical &amp;amp; elections and compared the final Democratic Party vote share. For these models, we trained the linear regression model, then added in the new 2022 forecasts. Using its now-trained knowledge, it applied it to each of the districts with current ratings. Spoiler alert: this is the most uninteresting thing I’ve done so far for this prediction… sadly.&lt;/p&gt;
&lt;p&gt;We begin with the Cook Political Report:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        group value
## 1 Republican   215
## 2   Democrat   220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/forecast-of-the-2022-midterm-elections/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
Based on the ratings from the Cook Political Report, we find quite a shocking result. When capturing in the ratings and accuracy of Cook &amp;amp; Democratic Party vote share, the R-squared value is 0.699, higher than the overall average, but not statistically different. As seen in the pie chart, the Democratic Party NARROWLY has the majority, with 220 seats to the Republican Party’s 215. This is a net decrease of 2 seats across the national map.&lt;/p&gt;
&lt;p&gt;Let’s move onto Larry Sabato’s Crystal Ball:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        group value
## 1 Republican   215
## 2   Democrat   220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/forecast-of-the-2022-midterm-elections/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;
How boring. We find in this model, the R-squared value is still significant, with it being 0.693. This is less than the Cook Political Report r-squared, but is still not statistically different from the prior model. As one can guess, this results in similar results, and we find an identical result of 220-215 seats (Democrats-Republicans).&lt;/p&gt;
&lt;p&gt;Let’s see if Inside Elections changes anything:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        group value
## 1 Republican   215
## 2   Democrat   220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/forecast-of-the-2022-midterm-elections/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;
Of course… not. I promise you, when you go to the district-by-district ratings, there are differences in regards of percentage points. However, since we are not working with a 7 point scale on our actual results, the difference in outcome is not differeet across these 3 forecasters. In regards to Inside Elections, they find, again, an identical result of 220-215 (Democratic to Republican seats).&lt;/p&gt;
&lt;p&gt;While we should not expect much, lets head into a 2022 combination model based on these expert forecasts.&lt;/p&gt;
&lt;p&gt;== Conclusive Model ==&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##                                               
## 1 function (x, df1, df2, ncp, log = FALSE)    
## 2 {                                           
## 3     if (missing(ncp))                       
## 4         .Call(C_df, x, df1, df2, log)       
## 5     else .Call(C_dnf, x, df1, df2, ncp, log)
## 6 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/forecast-of-the-2022-midterm-elections/index.en_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can expect, the combination model turned up with exactly what all of the other models were telling us: 220 D - 215 R. This is not the result that I was expecting, but it is one that may be close to the actual result. As mentioned previously, the R-squared value of the model is 0.697. This is quite significant, though far from perfect. This result is shocking, to say the least, but there is a possibility for movement within the model. Let’s explore that next.&lt;/p&gt;
&lt;p&gt;== Limitations, Model Validation, and Uncertainty Around My Prediction ==&lt;/p&gt;
&lt;p&gt;This model, while not perfect, does shine a light a bit on how competitive these midterm elections truly are. The Democrats and Republicans are neck-and-neck in the national generic ballot, and numerous shifts have been happening left and rights. While I do not personally agree with the outcome, a 220-215 result may only be 20-30 seats off from the actual results. Let’s talk about some limitations that likely negatively impacted this model.&lt;/p&gt;
&lt;p&gt;To begin, there was always going to be a limitation with our data on two fronts: utilize just 3 ratings websites &amp;amp; the time frame of which we compared ratings to results. In using Cook, Sabato, and Inside Elections, we find ourselves restricting the forecast to just 3 expert ratings. A simple Google search can show you tens of forecasters with established and respected sites – websites such as the Economist or FiveThirtyEight – all of them have a say in this election as well. By negating their input, we likely ended up with a more-inaccurate model. On top of this, we find that by only comparing ratings to results in the past 10 years, we are limiting our understanding of the accuracy of these predictions. Truly put – it would be much better to have 30-40 years of comparison, but these pundits have not even been around for that long. It would prove to be an impossible task, at least with all 3 of these forecasters, to date back before the 21st Century – even if it may prove to be heplful in this final forecast.&lt;/p&gt;
&lt;p&gt;Other limitations may include inaccurate reporting of ratings – while I trust the sources I utilized for these expert forecasts, there is a possibility that some were misinterpreted, outdated, etc. The ratings were found directly from the official websites or from officials within these organizations, but this does not garuntee human error did not play a role. I hand-entered all of the ratings into a .csv to utilize for this project, and considering how these relationships are found in a linear regression model, it is possible a few errors could have completely thrown off the&lt;/p&gt;
&lt;p&gt;As it pertains to uncertainty around my prediction, my predictive interval can be found here (it may not fully load without R loaded… Github is tricky to display this all):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 435 Columns: 8
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (4): district_id, cpr, inside_elections, crystal_ball
## dbl (4): cpr_num, inside_elections_num, crystal_ball_num, avg
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          fit       lwr      upr
## 1   59.07461 33.771416 84.37781
## 2   30.92908  5.620342 56.23782
## 3   30.92908  5.620342 56.23782
## 4   30.92908  5.620342 56.23782
## 5   30.92908  5.620342 56.23782
## 6   30.92908  5.620342 56.23782
## 7   30.92908  5.620342 56.23782
## 8   73.14738 47.837934 98.45683
## 9   30.92908  5.620342 56.23782
## 10  30.92908  5.620342 56.23782
## 11  30.92908  5.620342 56.23782
## 12  30.92908  5.620342 56.23782
## 13  47.34731 22.044724 72.64989
## 14  45.00185 19.698885 70.30481
## 15  73.14738 47.837934 98.45683
## 16  63.76554 38.460923 89.07015
## 17  30.92908  5.620342 56.23782
## 18  45.00185 19.698885 70.30481
## 19  73.14738 47.837934 98.45683
## 20  30.92908  5.620342 56.23782
## 21  30.92908  5.620342 56.23782
## 22  30.92908  5.620342 56.23782
## 23  73.14738 47.837934 98.45683
## 24  37.96546 12.660365 63.27056
## 25  73.14738 47.837934 98.45683
## 26  30.92908  5.620342 56.23782
## 27  73.14738 47.837934 98.45683
## 28  73.14738 47.837934 98.45683
## 29  73.14738 47.837934 98.45683
## 30  63.76554 38.460923 89.07015
## 31  73.14738 47.837934 98.45683
## 32  73.14738 47.837934 98.45683
## 33  73.14738 47.837934 98.45683
## 34  54.38369 29.081240 79.68614
## 35  73.14738 47.837934 98.45683
## 36  73.14738 47.837934 98.45683
## 37  73.14738 47.837934 98.45683
## 38  73.14738 47.837934 98.45683
## 39  73.14738 47.837934 98.45683
## 40  73.14738 47.837934 98.45683
## 41  30.92908  5.620342 56.23782
## 42  73.14738 47.837934 98.45683
## 43  52.03823 26.735902 77.34056
## 44  30.92908  5.620342 56.23782
## 45  73.14738 47.837934 98.45683
## 46  70.80192 45.493932 96.10991
## 47  70.80192 45.493932 96.10991
## 48  49.69277 24.390397 74.99514
## 49  73.14738 47.837934 98.45683
## 50  73.14738 47.837934 98.45683
## 51  73.14738 47.837934 98.45683
## 52  73.14738 47.837934 98.45683
## 53  73.14738 47.837934 98.45683
## 54  73.14738 47.837934 98.45683
## 55  73.14738 47.837934 98.45683
## 56  73.14738 47.837934 98.45683
## 57  73.14738 47.837934 98.45683
## 58  73.14738 47.837934 98.45683
## 59  73.14738 47.837934 98.45683
## 60  73.14738 47.837934 98.45683
## 61  37.96546 12.660365 63.27056
## 62  37.96546 12.660365 63.27056
## 63  73.14738 47.837934 98.45683
## 64  73.14738 47.837934 98.45683
## 65  73.14738 47.837934 98.45683
## 66  45.00185 19.698885 70.30481
## 67  73.14738 47.837934 98.45683
## 68  59.07461 33.771416 84.37781
## 69  30.92908  5.620342 56.23782
## 70  56.72915 31.426411 82.03190
## 71  73.14738 47.837934 98.45683
## 72  73.14738 47.837934 98.45683
## 73  73.14738 47.837934 98.45683
## 74  73.14738 47.837934 98.45683
## 75  73.14738 47.837934 98.45683
## 76  33.27454  7.967183 58.58190
## 77  30.92908  5.620342 56.23782
## 78  30.92908  5.620342 56.23782
## 79  73.14738 47.837934 98.45683
## 80  63.76554 38.460923 89.07015
## 81  52.03823 26.735902 77.34056
## 82  73.14738 47.837934 98.45683
## 83  68.45646 43.149762 93.76316
## 84  73.14738 47.837934 98.45683
## 85  73.14738 47.837934 98.45683
## 86  56.72915 31.426411 82.03190
## 87  73.14738 47.837934 98.45683
## 88  30.92908  5.620342 56.23782
## 89  30.92908  5.620342 56.23782
## 90  30.92908  5.620342 56.23782
## 91  30.92908  5.620342 56.23782
## 92  33.27454  7.967183 58.58190
## 93  30.92908  5.620342 56.23782
## 94  33.27454  7.967183 58.58190
## 95  30.92908  5.620342 56.23782
## 96  73.14738 47.837934 98.45683
## 97  73.14738 47.837934 98.45683
## 98  30.92908  5.620342 56.23782
## 99  30.92908  5.620342 56.23782
## 100 37.96546 12.660365 63.27056
## 101 73.14738 47.837934 98.45683
## 102 37.96546 12.660365 63.27056
## 103 30.92908  5.620342 56.23782
## 104 30.92908  5.620342 56.23782
## 105 30.92908  5.620342 56.23782
## 106 30.92908  5.620342 56.23782
## 107 73.14738 47.837934 98.45683
## 108 30.92908  5.620342 56.23782
## 109 73.14738 47.837934 98.45683
## 110 73.14738 47.837934 98.45683
## 111 73.14738 47.837934 98.45683
## 112 73.14738 47.837934 98.45683
## 113 30.92908  5.620342 56.23782
## 114 40.31093 15.006705 65.61515
## 115 30.92908  5.620342 56.23782
## 116 30.92908  5.620342 56.23782
## 117 68.45646 43.149762 93.76316
## 118 30.92908  5.620342 56.23782
## 119 73.14738 47.837934 98.45683
## 120 73.14738 47.837934 98.45683
## 121 33.27454  7.967183 58.58190
## 122 73.14738 47.837934 98.45683
## 123 30.92908  5.620342 56.23782
## 124 30.92908  5.620342 56.23782
## 125 30.92908  5.620342 56.23782
## 126 30.92908  5.620342 56.23782
## 127 30.92908  5.620342 56.23782
## 128 73.14738 47.837934 98.45683
## 129 30.92908  5.620342 56.23782
## 130 73.14738 47.837934 98.45683
## 131 73.14738 47.837934 98.45683
## 132 42.65639 17.352879 67.95989
## 133 42.65639 17.352879 67.95989
## 134 47.34731 22.044724 72.64989
## 135 30.92908  5.620342 56.23782
## 136 30.92908  5.620342 56.23782
## 137 30.92908  5.620342 56.23782
## 138 73.14738 47.837934 98.45683
## 139 73.14738 47.837934 98.45683
## 140 73.14738 47.837934 98.45683
## 141 73.14738 47.837934 98.45683
## 142 73.14738 47.837934 98.45683
## 143 66.11100 40.805426 91.41657
## 144 73.14738 47.837934 98.45683
## 145 73.14738 47.837934 98.45683
## 146 73.14738 47.837934 98.45683
## 147 73.14738 47.837934 98.45683
## 148 68.45646 43.149762 93.76316
## 149 30.92908  5.620342 56.23782
## 150 59.07461 33.771416 84.37781
## 151 63.76554 38.460923 89.07015
## 152 30.92908  5.620342 56.23782
## 153 30.92908  5.620342 56.23782
## 154 54.38369 29.081240 79.68614
## 155 54.38369 29.081240 79.68614
## 156 30.92908  5.620342 56.23782
## 157 30.92908  5.620342 56.23782
## 158 30.92908  5.620342 56.23782
## 159 30.92908  5.620342 56.23782
## 160 30.92908  5.620342 56.23782
## 161 73.14738 47.837934 98.45683
## 162 30.92908  5.620342 56.23782
## 163 30.92908  5.620342 56.23782
## 164 30.92908  5.620342 56.23782
## 165 30.92908  5.620342 56.23782
## 166 56.72915 31.426411 82.03190
## 167 30.92908  5.620342 56.23782
## 168 30.92908  5.620342 56.23782
## 169 30.92908  5.620342 56.23782
## 170 73.14738 47.837934 98.45683
## 171 30.92908  5.620342 56.23782
## 172 30.92908  5.620342 56.23782
## 173 30.92908  5.620342 56.23782
## 174 30.92908  5.620342 56.23782
## 175 73.14738 47.837934 98.45683
## 176 30.92908  5.620342 56.23782
## 177 30.92908  5.620342 56.23782
## 178 30.92908  5.620342 56.23782
## 179 30.92908  5.620342 56.23782
## 180 73.14738 47.837934 98.45683
## 181 73.14738 47.837934 98.45683
## 182 73.14738 47.837934 98.45683
## 183 73.14738 47.837934 98.45683
## 184 73.14738 47.837934 98.45683
## 185 73.14738 47.837934 98.45683
## 186 73.14738 47.837934 98.45683
## 187 73.14738 47.837934 98.45683
## 188 73.14738 47.837934 98.45683
## 189 30.92908  5.620342 56.23782
## 190 73.14738 47.837934 98.45683
## 191 73.14738 47.837934 98.45683
## 192 73.14738 47.837934 98.45683
## 193 73.14738 47.837934 98.45683
## 194 63.76554 38.460923 89.07015
## 195 73.14738 47.837934 98.45683
## 196 73.14738 47.837934 98.45683
## 197 73.14738 47.837934 98.45683
## 198 54.38369 29.081240 79.68614
## 199 30.92908  5.620342 56.23782
## 200 30.92908  5.620342 56.23782
## 201 59.07461 33.771416 84.37781
## 202 30.92908  5.620342 56.23782
## 203 30.92908  5.620342 56.23782
## 204 73.14738 47.837934 98.45683
## 205 54.38369 29.081240 79.68614
## 206 56.72915 31.426411 82.03190
## 207 30.92908  5.620342 56.23782
## 208 42.65639 17.352879 67.95989
## 209 73.14738 47.837934 98.45683
## 210 73.14738 47.837934 98.45683
## 211 73.14738 47.837934 98.45683
## 212 35.62000 10.313858 60.92615
## 213 52.03823 26.735902 77.34056
## 214 73.14738 47.837934 98.45683
## 215 73.14738 47.837934 98.45683
## 216 73.14738 47.837934 98.45683
## 217 30.92908  5.620342 56.23782
## 218 30.92908  5.620342 56.23782
## 219 30.92908  5.620342 56.23782
## 220 73.14738 47.837934 98.45683
## 221 30.92908  5.620342 56.23782
## 222 30.92908  5.620342 56.23782
## 223 30.92908  5.620342 56.23782
## 224 73.14738 47.837934 98.45683
## 225 30.92908  5.620342 56.23782
## 226 30.92908  5.620342 56.23782
## 227 30.92908  5.620342 56.23782
## 228 30.92908  5.620342 56.23782
## 229 73.14738 47.837934 98.45683
## 230 30.92908  5.620342 56.23782
## 231 30.92908  5.620342 56.23782
## 232 45.00185 19.698885 70.30481
## 233 30.92908  5.620342 56.23782
## 234 63.76554 38.460923 89.07015
## 235 73.14738 47.837934 98.45683
## 236 30.92908  5.620342 56.23782
## 237 73.14738 47.837934 98.45683
## 238 30.92908  5.620342 56.23782
## 239 68.45646 43.149762 93.76316
## 240 30.92908  5.620342 56.23782
## 241 30.92908  5.620342 56.23782
## 242 30.92908  5.620342 56.23782
## 243 30.92908  5.620342 56.23782
## 244 30.92908  5.620342 56.23782
## 245 73.14738 47.837934 98.45683
## 246 49.69277 24.390397 74.99514
## 247 73.14738 47.837934 98.45683
## 248 30.92908  5.620342 56.23782
## 249 30.92908  5.620342 56.23782
## 250 49.69277 24.390397 74.99514
## 251 30.92908  5.620342 56.23782
## 252 56.72915 31.426411 82.03190
## 253 63.76554 38.460923 89.07015
## 254 73.14738 47.837934 98.45683
## 255 30.92908  5.620342 56.23782
## 256 68.45646 43.149762 93.76316
## 257 30.92908  5.620342 56.23782
## 258 68.45646 43.149762 93.76316
## 259 73.14738 47.837934 98.45683
## 260 45.00185 19.698885 70.30481
## 261 73.14738 47.837934 98.45683
## 262 73.14738 47.837934 98.45683
## 263 73.14738 47.837934 98.45683
## 264 73.14738 47.837934 98.45683
## 265 73.14738 47.837934 98.45683
## 266 70.80192 45.493932 96.10991
## 267 52.03823 26.735902 77.34056
## 268 68.45646 43.149762 93.76316
## 269 56.72915 31.426411 82.03190
## 270 30.92908  5.620342 56.23782
## 271 54.38369 29.081240 79.68614
## 272 59.07461 33.771416 84.37781
## 273 45.00185 19.698885 70.30481
## 274 40.31093 15.006705 65.61515
## 275 56.72915 31.426411 82.03190
## 276 59.07461 33.771416 84.37781
## 277 73.14738 47.837934 98.45683
## 278 73.14738 47.837934 98.45683
## 279 73.14738 47.837934 98.45683
## 280 73.14738 47.837934 98.45683
## 281 73.14738 47.837934 98.45683
## 282 73.14738 47.837934 98.45683
## 283 37.96546 12.660365 63.27056
## 284 73.14738 47.837934 98.45683
## 285 73.14738 47.837934 98.45683
## 286 73.14738 47.837934 98.45683
## 287 73.14738 47.837934 98.45683
## 288 73.14738 47.837934 98.45683
## 289 56.72915 31.426411 82.03190
## 290 59.07461 33.771416 84.37781
## 291 52.03823 26.735902 77.34056
## 292 73.14738 47.837934 98.45683
## 293 30.92908  5.620342 56.23782
## 294 52.03823 26.735902 77.34056
## 295 30.92908  5.620342 56.23782
## 296 30.92908  5.620342 56.23782
## 297 73.14738 47.837934 98.45683
## 298 73.14738 47.837934 98.45683
## 299 52.03823 26.735902 77.34056
## 300 30.92908  5.620342 56.23782
## 301 73.14738 47.837934 98.45683
## 302 30.92908  5.620342 56.23782
## 303 30.92908  5.620342 56.23782
## 304 30.92908  5.620342 56.23782
## 305 30.92908  5.620342 56.23782
## 306 30.92908  5.620342 56.23782
## 307 59.07461 33.771416 84.37781
## 308 30.92908  5.620342 56.23782
## 309 73.14738 47.837934 98.45683
## 310 30.92908  5.620342 56.23782
## 311 52.03823 26.735902 77.34056
## 312 30.92908  5.620342 56.23782
## 313 30.92908  5.620342 56.23782
## 314 30.92908  5.620342 56.23782
## 315 30.92908  5.620342 56.23782
## 316 30.92908  5.620342 56.23782
## 317 30.92908  5.620342 56.23782
## 318 30.92908  5.620342 56.23782
## 319 73.14738 47.837934 98.45683
## 320 30.92908  5.620342 56.23782
## 321 73.14738 47.837934 98.45683
## 322 59.07461 33.771416 84.37781
## 323 52.03823 26.735902 77.34056
## 324 54.38369 29.081240 79.68614
## 325 33.27454  7.967183 58.58190
## 326 73.14738 47.837934 98.45683
## 327 73.14738 47.837934 98.45683
## 328 73.14738 47.837934 98.45683
## 329 73.14738 47.837934 98.45683
## 330 70.80192 45.493932 96.10991
## 331 52.03823 26.735902 77.34056
## 332 52.03823 26.735902 77.34056
## 333 30.92908  5.620342 56.23782
## 334 30.92908  5.620342 56.23782
## 335 30.92908  5.620342 56.23782
## 336 68.45646 43.149762 93.76316
## 337 30.92908  5.620342 56.23782
## 338 30.92908  5.620342 56.23782
## 339 30.92908  5.620342 56.23782
## 340 30.92908  5.620342 56.23782
## 341 52.03823 26.735902 77.34056
## 342 73.14738 47.837934 98.45683
## 343 54.38369 29.081240 79.68614
## 344 30.92908  5.620342 56.23782
## 345 30.92908  5.620342 56.23782
## 346 30.92908  5.620342 56.23782
## 347 30.92908  5.620342 56.23782
## 348 30.92908  5.620342 56.23782
## 349 73.14738 47.837934 98.45683
## 350 30.92908  5.620342 56.23782
## 351 30.92908  5.620342 56.23782
## 352 30.92908  5.620342 56.23782
## 353 30.92908  5.620342 56.23782
## 354 30.92908  5.620342 56.23782
## 355 30.92908  5.620342 56.23782
## 356 35.62000 10.313858 60.92615
## 357 30.92908  5.620342 56.23782
## 358 30.92908  5.620342 56.23782
## 359 30.92908  5.620342 56.23782
## 360 73.14738 47.837934 98.45683
## 361 30.92908  5.620342 56.23782
## 362 30.92908  5.620342 56.23782
## 363 30.92908  5.620342 56.23782
## 364 30.92908  5.620342 56.23782
## 365 30.92908  5.620342 56.23782
## 366 30.92908  5.620342 56.23782
## 367 73.14738 47.837934 98.45683
## 368 30.92908  5.620342 56.23782
## 369 73.14738 47.837934 98.45683
## 370 30.92908  5.620342 56.23782
## 371 30.92908  5.620342 56.23782
## 372 30.92908  5.620342 56.23782
## 373 30.92908  5.620342 56.23782
## 374 30.92908  5.620342 56.23782
## 375 40.31093 15.006705 65.61515
## 376 73.14738 47.837934 98.45683
## 377 30.92908  5.620342 56.23782
## 378 73.14738 47.837934 98.45683
## 379 30.92908  5.620342 56.23782
## 380 73.14738 47.837934 98.45683
## 381 30.92908  5.620342 56.23782
## 382 30.92908  5.620342 56.23782
## 383 30.92908  5.620342 56.23782
## 384 30.92908  5.620342 56.23782
## 385 30.92908  5.620342 56.23782
## 386 30.92908  5.620342 56.23782
## 387 30.92908  5.620342 56.23782
## 388 56.72915 31.426411 82.03190
## 389 73.14738 47.837934 98.45683
## 390 73.14738 47.837934 98.45683
## 391 30.92908  5.620342 56.23782
## 392 73.14738 47.837934 98.45683
## 393 73.14738 47.837934 98.45683
## 394 54.38369 29.081240 79.68614
## 395 73.14738 47.837934 98.45683
## 396 30.92908  5.620342 56.23782
## 397 73.14738 47.837934 98.45683
## 398 30.92908  5.620342 56.23782
## 399 30.92908  5.620342 56.23782
## 400 30.92908  5.620342 56.23782
## 401 30.92908  5.620342 56.23782
## 402 30.92908  5.620342 56.23782
## 403 30.92908  5.620342 56.23782
## 404 52.03823 26.735902 77.34056
## 405 73.14738 47.837934 98.45683
## 406 73.14738 47.837934 98.45683
## 407 30.92908  5.620342 56.23782
## 408 30.92908  5.620342 56.23782
## 409 56.72915 31.426411 82.03190
## 410 73.14738 47.837934 98.45683
## 411 30.92908  5.620342 56.23782
## 412 66.11100 40.805426 91.41657
## 413 73.14738 47.837934 98.45683
## 414 73.14738 47.837934 98.45683
## 415 73.14738 47.837934 98.45683
## 416 73.14738 47.837934 98.45683
## 417 42.65639 17.352879 67.95989
## 418 30.92908  5.620342 56.23782
## 419 30.92908  5.620342 56.23782
## 420 73.14738 47.837934 98.45683
## 421 73.14738 47.837934 98.45683
## 422 54.38369 29.081240 79.68614
## 423 73.14738 47.837934 98.45683
## 424 73.14738 47.837934 98.45683
## 425 30.92908  5.620342 56.23782
## 426 73.14738 47.837934 98.45683
## 427 40.31093 15.006705 65.61515
## 428 73.14738 47.837934 98.45683
## 429 30.92908  5.620342 56.23782
## 430 30.92908  5.620342 56.23782
## 431 30.92908  5.620342 56.23782
## 432 30.92908  5.620342 56.23782
## 433 30.92908  5.620342 56.23782
## 434 30.92908  5.620342 56.23782
## 435 30.92908  5.620342 56.23782&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;These seemingly are numbered by alphabetical &amp;amp; numeric order (i.e. 1 is Alaska At-Large, 8 is Alabama-07, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you can see, there is QUITE a significant lower and upper interval within these predictions. As we talk about limitations, this likely drives the reason why there is high uncertainty. With just 5 elections to base accuracy off of, it is very possible that the predictions could be wildely off from what is expected. If we were to consider the upcoming midterms as a potential fluke elections, we could see results close to the lower &amp;amp; upper levels of Democratic Party vote share.&lt;/p&gt;
&lt;p&gt;Altogether, there is much that could be improved upon given the proper resources (or potentially 10-20 years in the future). The problem with this project being conducted now is the limited data and limited understanding (in the modern age) of political data on a congressional level. Moving forward, I hope to update this forecast in 2024, with additional time to bypass some of the limitations, cross check data, and more.&lt;/p&gt;
&lt;p&gt;== Conclusion ==&lt;/p&gt;
&lt;p&gt;In conclusion, the model finds a results that would probably get any political pundit in trouble if they were to publish it. This means – I am counting on being wrong after tomorrow. But who knows? This model was focused on seeing how accurate &amp;amp; knowledgable the political predictors were when it came down to congressional races, and honestly, I expected more Republican seats than what we have. Though, because of the high uncertainty and high levels of difference between the lower and upper bounds, there is still A LOT of wiggleroom for Democrats and Republicans in these races.&lt;/p&gt;
&lt;p&gt;Though this model predicts a Democratic majority, the Democratic Party can still likely expect to lose the midterm elections. The good thing about the human voice behind a model such as this one, is that I recognize this model will likely be wrong. I am looking forward to reflecting onto the accuracy of this model (in a sense, a combination of other models, variables, etc.).&lt;/p&gt;
&lt;p&gt;Thank you so much for taking the time to read my final forecast – let’s see what happens :).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #7</title>
      <link>https://example.com/post/blog-post-7/</link>
      <pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-7/</guid>
      <description>


&lt;p&gt;== Final Blog Post Before Midterm Prediction ==&lt;/p&gt;
&lt;p&gt;This blog post will be the final one held before the Midterm Elections. We are in quite an exciting time as we enter into November 2022 – my next blog post will ultimately be my final prediction. As it stands currently, the Democrats are losing on the national popular vote (FiveThirtyEight + RealClearPolitics polls), they are losing in expert forecasts (in the House + nearly in the Senate), and this blog post will be focused on one thing: updating my 2022 model.&lt;/p&gt;
&lt;p&gt;This week’s blog extension gave the opportunity to work on updating my statistical model – and thus, I wanted to use this opportunity to predict the 2022 House Elections given the 2018 midterm elections. Previously, I had explored the accuracy of the 2018 midterms as it pertained to predictions from 2018 (I used the data to predict itself), but now, we will be moving up a level.&lt;/p&gt;
&lt;p&gt;To begin, we will start by modeling the accuracy of the 2018 &amp;amp; 2020 expert predictions + 2018 &amp;amp; 2020 results!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-7/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
What we find here is that there seems to be a clear, visual, correlation between the rating &amp;amp; the Democratic Party’s vote share. The Democrats do significantly better when the rating is around 1, which checks out, and significantly worse when the rating is around 7, which also makes sense. Altogether, we find that this usage of comparing rating vs. Democratic Party vote share should work as a predictor for the 2022 midterms.&lt;/p&gt;
&lt;p&gt;Now, we are going to include the 2022 midterm elections, in which the model will not be utilizing a pooled model – this is strictly based on the 2018 &amp;amp; 2020 expert ratings + final results. In our predictive model, we will only be provided with the expert ratings for each individual house district. We are pivoting to a prediction for the midterms given the extremely close nature of the November elections. This will tremendously help in figuring out my final prediction.&lt;/p&gt;
&lt;p&gt;Now, let’s move into predicting the 2022 midterms based on the 2018, 2020 election results.&lt;/p&gt;
&lt;p&gt;== 2022 Prediction ==&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##        group value
## 1 Republican   212
## 2   Democrat   223&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-7/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
As you can see above, the 2022 prediction based on the 2018/2020 expert predictions accuracy gives the Democratic Party 223 seats, to the Republican Party’s 212. This would be a tremendous over performance for national Democrats, allowing them to EXPAND their House majority, relative to where it is today. This has rarely ever happened in the past 40 years, where typically incumbent parties LOSE control of one or both chambers in the U.S. Congress.&lt;/p&gt;
&lt;p&gt;This model shows a completely different result than what we would expect – but there is likely reasons for this. Roe v Wade was overturned this Summer, which has proven to throw the Republican party into turmoil. Special elections, fundraising records, and polls have indicated a better national environment for Democrats than before the Supreme Court’s decision. Democrats now face a higher-than-normal opportunity at expanding control of the Senate &amp;amp; potentially maintaining control of the House. If this forecast shows anything, it tells us that this Roevember bump is very much expected.&lt;/p&gt;
&lt;p&gt;However, with any out-of-ordinary prediction, it is very possible there is error that came with it. In this case, we should explore the limitations and potentially what is holding this model back from its full potential.&lt;/p&gt;
&lt;p&gt;== Exploring Potential Limitations ==&lt;/p&gt;
&lt;p&gt;When looking at how we predicted our 2022 elections based on the 2018 midterms, we fail to capture in the complexities of election analysis and prediction. Unfortunately for the Democrats, things aren’t as simple as using just 1 election as the basis for our prediction. We are not capturing in more than just 1 election of data, and thus, skews and flukes in this midterm will be calculated to be expected in 2022. This is not something we can treat as a traditional expectation, especially given 2018’s record breaking turnout + high Democratic Party vote share (nationwide). FiveThirtyEight even underestimated Democrats in 2018 – so expert ratings likely did as well. Unfortunately for the national Democratic Party, it may not be the case this time around.&lt;/p&gt;
&lt;p&gt;Here is a list form of the limitations that could be contributing to the Democratic Party’s unexpected, shocking victory within this blog post.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Not enough year to back up the forecast – by using 2018 data solely, we are limiting our ability to understand the election.&lt;/li&gt;
&lt;li&gt;We used only 3 different sources – unfortunately, only these 3 data sources had easily accessible data to pull for this blog post, so they were prioritized. However, they do not provide the universal input that one could hope for in a fine tuned model (given unlimited time + a work force behind them).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are many other variables/factors to discuss in terms of inaccuracies as we use this model, but overall, I do trust the beliefs of the masses to some extent. I do believe that the expert forecasts are going to be more correct/closer to the eventual result as we add in more data. However, in this case, I do not trust the model’s output of 223D to 212R.&lt;/p&gt;
&lt;p&gt;== Conclusion ==&lt;/p&gt;
&lt;p&gt;Though I did not pursue with the traditional blog extension for this post, using the ending of the blog extension has given me a good amout of time to work on my final prediction. Building out my model has taken some time &amp;amp; finalizing on an expert forecast model is something that I only recently thought of. I am excited to see how accurate the final model is as I continue till election day. I’m looking forward to watching the results come in at the IOP! I believe that my model will adjust itself over the next week &amp;amp; come back more refined &amp;amp; accurate.&lt;/p&gt;
&lt;p&gt;Thank you for taking the time to read this blog post :) Happy voting!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #6 - Ground Game</title>
      <link>https://example.com/post/blog-post-6-ground-game/</link>
      <pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-6-ground-game/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Throughout the 21st Century, turnout across the United States has fluctuated significantly. For the sake of this blog post, voter turnout is described as the % of the amount of voters vs. the voting eligible population (18+ &amp;amp; have the ability to vote). Taking data from the University of California Santa Barbara’s American Presidency Project, which collects data pertaining to presidential elections, we find that in the 2000 election, voter turnout was just 55.3%. Based on ElectProject.org, in the 2020 election, voter turnout was 66.6%; the highest since the 1900 presidential election.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;However, our focus is on the 2022 midterm elections &amp;amp; understanding the impact of turnout on congressional races. For the sake of context, turnout in 2018 was 50.0%, contrary to 2014’s turnout at 36.7%. Both of these races have something in common: they are midterm elections. Midterm elections rarely rival presidential election turnout — but when they do, elections become significantly more interesting.

The old rule of thumb was that increasing turnout meant an increase in Democratic vote share. Many pundits have been under the assumption that democrats rely heavily on turnout in order to win their elections, whereas republicans are the baseline winners. Taking 2014 &amp;amp; 2018 for instance — 2014 was an overwhelming red wave year, where Democrats were far from enthused &amp;amp; didn’t turnout. 2018, on the other hand, was a significantly high turnout year, in which Democrats won back control of the House of Representatives. Though, it is not that simple.

In this blog, we will be exploring the impact of turnout on the midterm elections, though we will be considering more than just that. In addition to turnout, we will be mapping our data based on expert predictions and incumbency. In this blog post, we will be utilizing 2018 as our data point — given that we are only using data for all 435 districts for 2018. For incumbency, we will be treating that as a factor by congressional district, denoting incumbency by the incumbent party in the district (even if the race is an open seat). Finally, our expert predictions will be taken from the Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;background-on-2018-midterm-elections&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background on 2018 Midterm Elections&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;To start, here are 2 maps of the 2018 midterm election results, as a baseline to see the election results. The first will show the margin of Democratic Party vote share, whereas the other will show the election winner in red or blue.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in sprintf(&amp;quot;https://cdmaps.polisci.ucla.edu/shp/districts114.zip&amp;quot;, :
## one argument not used by format &amp;#39;https://cdmaps.polisci.ucla.edu/shp/
## districts114.zip&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in sprintf(&amp;quot;districtShapes/districts114.shp&amp;quot;, cong): one argument not
## used by format &amp;#39;districtShapes/districts114.shp&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Reading layer `districts114&amp;#39; from data source 
##   `/private/var/folders/15/62drzq6146bd63l1qfb1btkr0000gn/T/RtmpRnIk6r/districtShapes/districts114.shp&amp;#39; 
##   using driver `ESRI Shapefile&amp;#39;
## Simple feature collection with 436 features and 15 fields (with 1 geometry empty)
## Geometry type: MULTIPOLYGON
## Dimension:     XY
## Bounding box:  xmin: -179.1473 ymin: 18.91383 xmax: 179.7785 ymax: 71.35256
## Geodetic CRS:  NAD83&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 16067 Columns: 31
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;,&amp;quot;
## chr (16): Office, State, Area, RepCandidate, RepStatus, DemCandidate, DemSta...
## dbl (14): raceYear, RepVotes, DemVotes, ThirdVotes, OtherVotes, PluralityVot...
## lgl  (1): CensusPop
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
## `summarise()` has grouped output by &amp;#39;district_num&amp;#39;, &amp;#39;State&amp;#39;, &amp;#39;district_id&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 22.80 64.41 49.59 50.62 38.84 68.25&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 method overwritten by &amp;#39;geojsonlint&amp;#39;:
##   method         from 
##   print.location dplyr&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] (0,50]   (50,100] (0,50]   (50,100] (0,50]   (50,100]
## Levels: (0,50] (50,100]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;
Note on the map above: some of the districts are grayed out (only 3), this is due to a data error not being captured by the R code mapping the districts. These are all Republican victories – please view them as such.&lt;/p&gt;
&lt;p&gt;Overall, Democrats captured 235 House seats, to the Republican Party’s 199. This was the most recent midterm election result.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-on-expert-prediction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model on expert prediction&lt;/h2&gt;
&lt;p&gt;Now, we move onto expert predictions for 2018 &amp;amp; see what worked versus did not. Here is a map of the 2018 predictions on the House level.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 7.000000 1.000000 3.666667 3.666667 3.666667 3.666667&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: gridExtra&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;gridExtra&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:dplyr&amp;#39;:
## 
##     combine&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on the results above, we find that expert predictions are not too far off from reality. The results vs. the expected are nearly identitcal – with very similar maps. There are some differences, but ultimately, expert predictions are quite reliable.&lt;/p&gt;
&lt;p&gt;Unfortunately, expert predictions are not always going to be the most “ethical” way to go about political predictions. In a sense, it is cheating, as the factors we include, such as GDP growth, presidential approval, incumbency, etc. are all taken into account through the expert forecasts. Thus, if we create a forecast with 5-10 variables impacting the prediction, while including an expert rating that already does that, we could be over-doing the forecast. Though, expert predictions on its own, could be fascinating to explore.&lt;/p&gt;
&lt;p&gt;Ironically, we are going to move into expert predictions + incumbency as it pertains to Dem vote share.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-including-incumbency-expert-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model including incumbency + expert predictions&lt;/h2&gt;
&lt;p&gt;To begin, let’s explore the correlation between the ratings from political firms &amp;amp; the Democratic Party’s vote share:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Dem_votes_pct ~ avg, data = expertratings)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.557  -7.208  -0.767   5.473  24.972 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  81.7734     0.9238   88.52   &amp;lt;2e-16 ***
## avg          -6.7452     0.1982  -34.04   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 11.05 on 434 degrees of freedom
## Multiple R-squared:  0.7275, Adjusted R-squared:  0.7268 
## F-statistic:  1159 on 1 and 434 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the found R^2 of 0.7275, we can conclude that there is correlation between Democratic Party vote share and expert rating. This correlation indicates that expert ratings are good at providing helpful insight into the outcome of elections on the Congressional level.&lt;/p&gt;
&lt;p&gt;At this point in the blog post, we will be shifting from predictions, to rather analyzing the correlation between our extended variables and the 2018 election results. This is because I do not plan to include any of the future variables in my final prediction – however, knowing how they are connected to Democratic Party vote share is equally fascinating as it is important. Now, let’s throw in the factor of incumbency into the mix in addition to expert predictions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Dem_votes_pct ~ avg + IncumbentParty, data = newdatafr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.948  -6.166  -0.558   5.257  24.224 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)     81.5211     0.9145  89.144  &amp;lt; 2e-16 ***
## avg             -5.7455     0.3667 -15.666  &amp;lt; 2e-16 ***
## IncumbentParty  -6.3544     1.9724  -3.222  0.00137 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 10.92 on 435 degrees of freedom
## Multiple R-squared:  0.7334, Adjusted R-squared:  0.7322 
## F-statistic: 598.4 on 2 and 435 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The R^2 in this was 0.7334, which was an increase from the previous R^2 value under just expert predictions. By adding in the incumbent party (currently holding the seat), the R^2 shows a clear correlation between the two variables when added together. This is to be expected, as mentioned previously, as expert predictions practically cover forecasters on many fronts.&lt;/p&gt;
&lt;p&gt;I expect it to be the same as we add in the factor of turnout.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-including-incumbency-expert-predictions-turnout&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model including incumbency + expert predictions + turnout&lt;/h2&gt;
&lt;p&gt;Before we look at turnout, I want to plot a simple map of turnout by congressional district in 2018, just for additional context.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.43 0.54 0.49 0.49 0.54 0.54&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-6-ground-game/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;
As shown in the map, most congressional districts experienced turnout between 40%-60%. This puts the majority of our districts within a similar turnout rate, thus making it more difficult to use it as a predictor. Despite the majority being 40%-60%, there are some extremely high turnout districts, such as Montana’s At-Large District, with 60%-80% turnout. Some, however, are on the flip side of low turnout: such as Texas’s 34th District, betwene 20%-40%. Main takeaway from this map: turnout is pretty standard when sectioned into blocks.&lt;/p&gt;
&lt;p&gt;Let’s run a linear regression model to find the correlation between Dem vote share &amp;amp; incumbency + turnout + expert predictions! The big 3!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Dem_votes_pct ~ avg + IncumbentParty + turnout, 
##     data = newdatafr)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -44.733  -6.700   0.244   5.981  27.275 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)      97.545      2.583  37.757  &amp;lt; 2e-16 ***
## avg              -5.990      0.352 -17.016  &amp;lt; 2e-16 ***
## IncumbentParty   -3.692      1.926  -1.917   0.0558 .  
## turnout         -34.236      5.195  -6.590 1.28e-10 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 10.43 on 434 degrees of freedom
## Multiple R-squared:  0.7577, Adjusted R-squared:  0.756 
## F-statistic: 452.4 on 3 and 434 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above model, the R^2 was found to be 0.756. This is quite significant in terms of correlation, showing how there is a correlation between incumbency, expert predictions, AND turnout. All 3 of the factors increase the correlation between the variables – getting it closer to 1, each time we added a new variable.&lt;/p&gt;
&lt;p&gt;Unfortunately, I will not be using turnout or incumbency in my final prediction, but for my 2022 forecast, I am now considering using expert predictions. Here is my prediction based on that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       50.4
##  2  2022 Arizona   1                       5     4       5.5     4.83       48.9
##  3  2022 Arizona   2                       5     5       5.5     5.17       48.1
##  4  2022 Arizona   4                       3     2       1.75    2.25       55.4
##  5  2022 Arizona   6                       5     5       4.75    4.92       48.7
##  6  2022 Californ… 3                       6     6       6.25    6.08       45.8
##  7  2022 Californ… 6                       1     1       1       1          58.5
##  8  2022 Californ… 9                       3     3       1.75    2.58       54.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        52.3
## 10  2022 Californ… 21                      2     1       1       1.33       57.7
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above chart, you can find the prediction for the 2022 congressional midterms based on expert ratings from the Cook Political Report, Sabato’s Crystal Ball, and Inside Elections.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;p&gt;The limitations of this blog post can be found in a number of ways. On one hand, our data utilizing only the 2018 election restricts the models ability to compare accuracy from previous elections (preferrably 2012-2020). By using 2018, we are restricted to a high-turnout, pro-Democratic party midterm election, rather than assessing a potentially (as 2022 may be) red-wave midterm or low-turnout midterm. However, I do believe that 2018 is closest to the actual district breakdown (some districts are different in the 2014 map) while serving as a basis from a midterm election.&lt;/p&gt;
&lt;p&gt;Another set of limitations deal directly with the sparse amounts of expert predictions &amp;amp; the restriction on the districts provided by the expert prediction data set. The data set provided by the course only has about 140 districts, rather than the traditional 435. On top of that, we narrowed our scope to 3 main forecasters, rather than include many more (the original data set included 10+). Though, I stand by my decision to utilize just the main 3.&lt;/p&gt;
&lt;p&gt;Beyond this, our turnout numbers were also restricted to 2018 – which was one of the midterms with extremely high turnout. In fact, 2018 turnout rivaled presidential election turnout in 2000 + 2004 (by raw vote #). This would be a limitation if 2022 was not expected to be a high-turnout midterm, but given the expected turnout, this was probably an okay decision.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;In conclusion, we can draw a significant connection between expert predictions, incumbency, and turnout to Democratic Party vote share. While this may be expected, we find this to be stated through our R^2 values and the code accompanying this blog post. As I reflect on my own 2022 model, I do not plan to utilize turnout or incumbency, as 1. we do not have turnout numbers for 2022 yet, and 2. incumbency typically matters for the President’s party, not the opposition. To code my model with the same factors would likely have to take a dramatically different form from it’s state in this blog – thus, I will likely not be including it in my final model.&lt;/p&gt;
&lt;p&gt;As for my takeaways &amp;amp; understandings of elections from this blog, I would say there are 3 main things we can takeaway:
1. Democratic party vote share is correlated with all the variables mentioned above
2. Expert predictions covers most of the correlation/connection between Dem vote share + incumbency, turnout, predictions
3. Our blog post was rooted in 2018, and while the turnout may be matched in 2022, this should not be applied to any midterms where turnout is expected to DROP below 2018-levels.&lt;/p&gt;
&lt;p&gt;Thank you for reading :) See you next week!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #4 - Predictions/Forecasts</title>
      <link>https://example.com/post/blog-post-4/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-4/</guid>
      <description>


&lt;p&gt;Expert predictions have been around in election analytics for decades. Predictions of election results have become a new market for various news agencies &amp;amp; websites to gain fame and popularity over correct predictions. Predictions also help inform an electorate of how a race may end up, well before the results are actually in. In the case of this blog post, we are going to be specifically focused on the 2018 midterm elections; we will be exploring the accuracy of the political pundits &amp;amp; what it means for competitive seats in these upcomimg November midterms (2022).&lt;/p&gt;
&lt;p&gt;In this blog, we will be focused on mostly swing/competitive districts for 2022, as described in our data sets. This data will be helpful to explore how accurate or inaccurate some of these experts are at forecasting the race. To narrow our field even more, we will only be utilizing the expert ratings from Inside Elections, Cook Political Report, and Larry Sabato’s Crystal Ball. Interestingly enough, I have actually met one of the leads at the Sabato Crystal Ball &amp;amp; spoke with Dave Wasserman, a head at the Cook Political Report. These are trustworthy forecasters, some of which have nailed past midterms &amp;amp; presidential elections; thus, my intial expectation for the upcoming midterms is that these predictions will be very accurate.&lt;/p&gt;
&lt;p&gt;Additionally, this blog post utilizes a numeric system for ratings, from 1-7. 1 being the safest for the DEMOCRATIC PARTY &amp;amp; 7 being the safest for the REPUBLICAN PARTY. Some ratings in the data set utilize a 9-point scale (traditionally, most use 7), as a result of the inclusion of a new characterization: tilt. However, the dataset accounts for that &amp;amp; has scaled it to work within a 7 point scale. To my knowledge, only Inside Elections uses tilt for House ratings, whereas Cook &amp;amp; Sabato use (only) lean, likely, and safe/solid.&lt;/p&gt;
&lt;div id=&#34;beginning-my-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beginning my code&lt;/h2&gt;
&lt;p&gt;Before we begin, we should model the map of the 2018 midterm elections by Democratic Party voteshare on a district-by-district map. We utilized shape files from the University of California, Los Angeles, to help model our map.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-4/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We are going to compare the map above to what the expert ratings had to say for the map. Unfortunately, we had to cut out Alaska &amp;amp; Hawaii, as it would competely warp our map &amp;amp; make other parts of the map unrecognizable. This means we are modeling 3 less seats than would be traditionally modeled, should Alaska &amp;amp; Hawaii be included. As you can see based on the above map, there are STRONG Democratic pockets across the country, even some with nearly 100% of the vote going towards a Democrat. This is the case in uncontested house seats, where Democrats hold strong &amp;amp; Republicans have no chance at victory. Vice-versa with super bright RED districts, indicating a near 100% victory for the Republican there. Overall though, we see where purple &amp;amp; stronger Democratic share lies, especially on the East &amp;amp; West Coasts, but still support for Democrats throughout the nation.&lt;/p&gt;
&lt;p&gt;Below is the map of the 2018 midterms based on expert prediction.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-4/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
I chose different colors as the range of numbers for the ratings was 0-7, not 0-100 (like the map above this one). This made more sense for visualization &amp;amp; was a good way to track the two different maps.&lt;/p&gt;
&lt;p&gt;To quantify the R^2 value between expert predictions &amp;amp; Democratic Party vote share, I decided to run the lineral regression model to find my number.&lt;/p&gt;
&lt;p&gt;I began launching my code by sorting out the expert ratings for the 3 forecasters (will be referred to as CSI for the remainder of the blog post). I started by following a prediction based strictly on 2018’s forecast accuracy.&lt;/p&gt;
&lt;p&gt;I created a new dataset called “new_train_data_2018”, combining my data sets of the Democratic Party’s vote share in districts &amp;amp; the CSI ratings, all from 2018. This allowed me to use this as my baseline data &amp;amp; run a model to find the correlation between expert prediction and Democratic Vote share.&lt;/p&gt;
&lt;p&gt;The R^2 value was 0.8118 &amp;amp; told me there was a significant connection between the Democratic Party’s vote share &amp;amp; expert ratings. It showed above average accuracy &amp;amp; told me that I could trust my Big 3: Cook Political Report, Larry Sabato’s Crystal Ball, and Inside Elections. Using the 2018 accuracy, I decided to put my CSI to the test in predicting the 2022 midterms.&lt;/p&gt;
&lt;p&gt;Quick reminder: we are only predicting the “competitive” seats as outlined in the dataset.
Here are the 2022 predictions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       50.4
##  2  2022 Arizona   1                       5     4       5.5     4.83       48.9
##  3  2022 Arizona   2                       5     5       5.5     5.17       48.1
##  4  2022 Arizona   4                       3     2       1.75    2.25       55.4
##  5  2022 Arizona   6                       5     5       4.75    4.92       48.7
##  6  2022 Californ… 3                       6     6       6.25    6.08       45.8
##  7  2022 Californ… 6                       1     1       1       1          58.5
##  8  2022 Californ… 9                       3     3       1.75    2.58       54.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        52.3
## 10  2022 Californ… 21                      2     1       1       1.33       57.7
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make things better, I decided to take into account CSI data &amp;amp; accuracy for 2010 through 2018. This meant repeating the above (for 2018), but including 4 more elections! How exciting!&lt;/p&gt;
&lt;p&gt;We calculated the R^2 value of the 2010-2018 connection between prediction &amp;amp; Democratic Party vote share &amp;amp; found it to be 0.7. Not as correlated as 2018, but still pretty good. Then, we calculated 2022 predictions based on 2010-2018 accuracy.&lt;/p&gt;
&lt;p&gt;Here it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 141 × 8
##     year state     district sabatos_crystal…  cook rothenberg avg_csi prediction
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
##  1  2022 Alaska    AL                      4     4       4.75    4.25       48.1
##  2  2022 Arizona   1                       5     4       5.5     4.83       46.5
##  3  2022 Arizona   2                       5     5       5.5     5.17       45.6
##  4  2022 Arizona   4                       3     2       1.75    2.25       53.5
##  5  2022 Arizona   6                       5     5       4.75    4.92       46.3
##  6  2022 Californ… 3                       6     6       6.25    6.08       43.1
##  7  2022 Californ… 6                       1     1       1       1          56.9
##  8  2022 Californ… 9                       3     3       1.75    2.58       52.6
##  9  2022 Californ… 13                      4     4       2.5     3.5        50.2
## 10  2022 Californ… 21                      2     1       1       1.33       56.0
## # … with 131 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Overall, we found that the CSI ratings held up to be pretty good indicators of House elections, especially 2018. I am personally pleased by the result we have seen, but am unsure if I will be including expert ratings in my final forecast. I do think they could help, but I’m deliberating between a FiveThirtyEight-style forecast (in this case, I’d include the expert ratings), or a 2-3 factor model to see if I can accurately predict the midterms without utilizing all variables. Though, this blog post was quite fun, and added a lot to my personal understanding of the connections between punditry and results.&lt;/p&gt;
&lt;p&gt;Thanks for reading :)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #3 - Polling in America</title>
      <link>https://example.com/post/blog-post-3-polling-in-america/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-3-polling-in-america/</guid>
      <description>


&lt;p&gt;Throughout the 21st Century, political punditry and forecasing has been paramount to understanding our national, political environment. Forecasters have used a variety of methods to pinpoint and predict the outcome of future elections. With a significant, recent rise in data analysis, horserace polling, and punditry, election forecasting has risen in popularity as well. Websites such as FiveThirtyEight &amp;amp; the Economist have begun to publish reoccurring election forecasts, depending on the election year. Whether a midterm or presidential election, these sites provide predictions and estimations for both sides of aisle–-backed up by data and statistics.&lt;/p&gt;
&lt;p&gt;To accurately predict an election, however, pundits rely heavily on public, non-partisan polls to fuel their predictions. Polls are typically regarded as the single, most important predictor in any election–at least until 2016. In 2016, the polls were significantly off, dramatically reducing trust in the polling industry. As we move into the 2022 midterm elections, the apprehension behind polls is still apparent, though recent sucesses in 2018 &amp;amp; 2020 have quelled some fears.&lt;/p&gt;
&lt;p&gt;As mentioned above, FiveThirtyEight is a forecasting company that churns out election forecasts in every midterm &amp;amp; presdiential election post-2010, ran by Nate Silver. In their model, they hold many factors to be important in their modeling: basic partisanship, errors found in race-to-race, likely voters, timeline adjustment, house effects adjustment, and present-day issues (such as COVID-19’s impact on voting). They weigh these models using different measures depending on what is most important and accurate within predicting. However, there are significant factors that guide FiveThirtyEight’s forecast towards the right and left wing. These are what we call “fundamentals.” Fundamentals are factors beyond polling that contribute to the race’s outcome.&lt;/p&gt;
&lt;p&gt;Fundamentals can include: an incumbent’s margin of victory in past elections, fundraising, 538’s partisan lean, congressional approval, scandals, voting record, and a challenger’s quality. These factors aide in the decision-making process in FiveThirtyEight’s model, with an emphasis on incumbency (+ performance) and generic ballot polling data. Additionally, FiveThirtyEight utilizes 3 different models for their predictions: Lite (polling + CANTOR), Classic (include fundamentals), Deluxe (include expert forecasts). They weigh their polls &amp;amp; adjust it based on time frame–providing a more accurate prediction.&lt;/p&gt;
&lt;p&gt;G. Elliot Morris runs The Economist’s forecast for elections, relying heavily on their own fundamentals and indicators for their predictions. As we are focused on Congressional (House) elections for 2022, we will be looking at Morris &amp;amp; The Economist’s House Fundamentals: partisan voting history, campaign fundraising, and other factors, similar to FiveThirtyEight. Of course, they utilize the generic ballot as well for their overall indicators. The generic ballot is a shared trait through nearly all pundits and forecasters, as it is a considerable indicator of public support and sentiment towards both parties. We also find that The Economist uses district-level data as part of their fundamentals – FiveThirtyEight does something similar, but it we find both models are hyper-specific. As noted in their 2018 model, The Economist uses a Skew-T distribution.&lt;/p&gt;
&lt;p&gt;As for predictions on the presidential level, The Economist uses economic data (GDP), presidential approval, and more. This data serves as The Economist’s “fundamentals,” as the coined term in FiveThirtyEight’s forecast. Overall, The Economist finds itself weighing similar to FiveThirtyEight (and other forecasters… see DecisionDeskHQ, RaceToTheWhiteHouse, etc.). Though, they have their differences when it comes to weighting and decision-making behind factors to include in their predictions.&lt;/p&gt;
&lt;p&gt;Between the two, I would preference FiveThirtyEight over The Economist. While I do believe that both are relatively accurate forecasters, FiveThirtyEight seems to take into consideration more factors than The Economist. Just through a simple look through of their websites, FiveThirtyEight has more interactive portions of their model that provides the viewer a better understanding of their predictions. Additionally, I prefer the 3 levels of modelling to help compare &amp;amp; contrast predictions from Lite, Classic, and Deluxe. Having the different levels helps me understand the impact of solely polling, then fundamentals included, then finally, expert forecasts.&lt;/p&gt;
&lt;p&gt;In this blog post, we will be utilizing a FiveThirtyEight strategy to understanding the impact of polling &amp;amp; the economy on the midterm elections.&lt;/p&gt;
&lt;p&gt;To begin, we will explore the generic ballot final numbers in November and compare it to the actual results of the midterm election. For this blog post, we will be exploring “Incumbent Party Vote Share.”&lt;/p&gt;
&lt;div id=&#34;generic-ballot-value-vs-actual-over-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generic Ballot Value vs Actual Over Time&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the above graph, we find that there is a correlation between November polling data &amp;amp; final results for political parties. The question is… how strong is the correlation? To find this, we calculated the linear regression model of the relationship between incumbent president’s party vote &amp;amp; the incumbent president’s party polls in November, we find the R squared value to be 0.5843. This reveals we have a moderate relationship between the two variables, thus making the November polls a somewhat accurate predictor of the actual election.&lt;/p&gt;
&lt;p&gt;Following our finding of this moderate relationship, we decided to predict the 2022 midterms based on the Democratic Party’s current numbers in the FiveThirtyEight generic ballot. To set up this prediction, we used the model that formed the above graph, and included a new data frame of the Democratic Party’s numbers as of right now. The current D Party vote share in the generic ballot is 45.3%, and thus, we will use that as our input to predict the actual Democratic Party vote share. When using the model &amp;amp; the new input, we find our prediction to put the Democrats at 49.42% for the 2022 vote-share. This is an under performance from their popular vote share from 2018 &amp;amp; 2020, which we can likely conclude results in a democratic loss in the House this November.&lt;/p&gt;
&lt;p&gt;Now, we will look at the economy.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;moving-onto-economic-impacts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Moving onto Economic Impacts&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;
To use economic data, I decided to use GDP growth in the 2nd quarter of the year, to help us better match where the 2022 midterms currently are. Based on the 2nd quarter GDP growth, we created a linear regression model of the relationship between that same GDP growth percentage &amp;amp; the incumbent president’s vote share. In addition to the linear regression model, we created a graph to show the relationship between the variables. In both the visual &amp;amp; calculated linear regression R^2 value, we found no correlation between the two.&lt;/p&gt;
&lt;p&gt;The R-squared value was -0.012, and thus, is actually predicting worse than a standard line. As a result, we likely cannot rely on GDP growth as a means of predicting the midterm elections, as it does us a disservice. However, for the sake of it, we will calculate the expectation for Democrats based on the 2022 Quarter 2’s GDP growth (-0.9%). With this number, the model predicts Democrats will have 48.02% of the vote share. The economy can serve as an equivalent to one of FiveThrityEight’s “fundamentals.”&lt;/p&gt;
&lt;p&gt;Finally, we will combine both factors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;combined-economic-polling-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combined Economic + Polling Model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-3-polling-in-america/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
After combining both factors, we found the strength to return to a moderate correlation. The R-squared value was found to be 0.57, but this is largely led by the relationship between polling and actual numbers, rather than GDP. Having less of an R-squared value with BOTH variables added in than with JUST polling likely indicates GDP growth was detrimental to my model. In this combined model, it found that the Democratic Party’s expected vote share is 49.37%, not too far off either of the other models. However, I have some difficulty trusting the combined model, as GDP growth is certainly not the best variable for predicting the midterms.&lt;/p&gt;
&lt;p&gt;In conclusion, we have 3 main takeaways from this blog post:
1. Polls in November are pretty good at predicting the actual vote share in the election
2. GDP growth in quarter 2 isn’t good at predicting the actual vote share in the election
3. Democrats still likely lose the House based on all 3 of the models created&lt;/p&gt;
&lt;p&gt;As we move forward, I am looking to change my economic variables to make the model more accurate, or consider entirely scrapping it from the final model.&lt;/p&gt;
&lt;p&gt;Thank you for reading :)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #1</title>
      <link>https://example.com/post/blog-post-2/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-2/</guid>
      <description>


&lt;p&gt;===== Worked with: Claire, Amiel, Jen, Julia &amp;amp; asked Kiara for help =======&lt;/p&gt;
&lt;p&gt;In this blog post, we are going to explore the impact of political gerrymandering on the 2020 House of Representative elections. This blog post will contain 2 main graphics: Figure 1. The 2020 Seat Share Margin Across Each State &amp;amp; Figure 2. The 2020 Party Vote Margin Across Each State. The data we utilized has come from 2 main sources: 1. Lab data from the Gov 1347 class &amp;amp; 2. CQ Voting and Elections Collection.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-2/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;
To begin, we will look at the 2020 vote share margin across the country. The party vote share across the majority of states seems quite tame, however that is likely due to the vote share margin being such an expansive (-0.75, 0.75). The reason for the reduction in the vote share margin frame is because it is rare for a party to get anywhere close to 100% more of the vote than their opponents – as a result, I decided to utilize a range that is more possible (75% vote margin). However, you may notice South Dakota to be gray, this is because the Democrats did not run a candidate in 2020. It is fascinating to think about the fact South Dakota had a Democrat in Congress as recently as 2011. Just food for thought&lt;/p&gt;
&lt;p&gt;Our vote share map reveals that some states are pretty close by House vote share: NC, VA, GA, FL, AZ, NV, PA, MI, WI, IA, MN, and NH (among others). These, not by coincidence, happened to be swing states in the presidential election that coincided with these House elections. The takeaway from this map is that more-states-than-not are close and competitive on the vote-share side. So… from this, you’d expect it to be similar in terms of House Composition/Seat Share? Right?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-2/index.en_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;
Wrong. When we find the seat share margin map, we find that the majority of states have a extreme partisan compositions, whether that be for Republicans or Democrats. Innocently, we could think that this could be due to simple partisanship, but we saw how few states were truly extremely partisan. For example Maryland–which hasn’t voted for a Republican since 1984 (U.S. Election Atlas)–is heavily blue on our shaded map on both the vote share &amp;amp; seat share map, but this is not the case for many other states. Plainly put: Maryland is an outlier.&lt;/p&gt;
&lt;p&gt;Some major differences between vote marign and seat margin can be found in many, many states, but most notably Texas, Ohio, and the worst of all, North Carolina. Texas and Ohio have significantly redder compositions on the Seat Share margin map than on the Party Vote Margin. If you look at the actual party vote margin in Ohio, it is 52R-47D (Ohio Secretary of State Website), compared to the seat composition of 12R-4D (OH SOS). This is a prime example of extreme gerrymandering. Sadly, Ohio is not alone. Texas is another example of partisan gerrymandering, where Republicans won just 9 points more than the Democrats statewide (Texas Secretary of State Website), yet lead them 23-13 (TX SOS) in the House composition. The worst example on the map would have to be North Carolina, where Democrats won the popular vote, yet only won 5/13 House seats in the state. This extreme level of gerrymandering prevented the Democrats from winning a majority in North Carolina.&lt;/p&gt;
&lt;p&gt;To clarify some important parts of the seat share margin map: some states have one singular district, meaning that the result will always be one dark color on the seatshare margin map. For instance, Montana has 1 Representative, and though Republicans won by less than 15%, it still went to them, thus marking the map as solid red. To not confuse single-district states with gerrymandered ones, here are the single-district states in the United States (pre-2022 Redistricting Era): AK, DE, MT, ND, SD, VT, and WY.&lt;/p&gt;
&lt;p&gt;In conclusion, I could write on and on about the abundance of evidence of gerrymandering through our maps, but it would be ultimately be redundant. To wrap up, there are two main takeaways that this blog post has revealed: 1. Republicans gerrymander better than Democrats – or at least, have more gerrymandered states than Democrats, likely due to their heavy levels of victories back in 2010 (see: 2010 Election Results) – and it shows. &amp;amp; 2. Vote share and seat share does align in some states, showcasing that our system is not entirely screwed up.&lt;/p&gt;
&lt;p&gt;Altogether, our political system in the House of Representatives needs work to ensure fair representation. However, based on how engrained gerrymandering is in American political culture – I am far from hopeful.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blog Post #1</title>
      <link>https://example.com/post/blog-post-1/</link>
      <pubDate>Tue, 13 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/blog-post-1/</guid>
      <description>


&lt;p&gt;Question/Blog Extension we are going to be going through:
Heterogenous Predictive Power of the Economy.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Does the effect of the economy vary when we consider popular vote versus seat share as our outcome (dependent) variable?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Does the predictive power of economy change across time? If so, why?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To begin, this blog post will be dealing with data sets that have been filtered and combined through R. This blog post will be utilizing GDP Quarter 7 data from the midterm years 1962-2018. By my own discretion, I have removed the presidential election years, as the data set does not treat the “president_party” variable as the party going into the election, but rather the victor of the presidential election. Consequently, I felt it would be most beneficial if that was taken out of the equation for this blog post. Additionally, as this class is focused on the 2022 midterms, I hoped to utilize the midterm-only data to guage a better understanding of midterms.&lt;/p&gt;
&lt;p&gt;To sort our data, I combined economic data and House of Representatives election data. In addition, we filtered, then mutated the data to create two new variables within our blog: pres_party_seat_share and pres_party_vote_share. The seat share was defined as the # of seats for the president’s party divided by 435 (total # of seats in the U.S. House). This also explains the reasoning behind the year selection, beginning in 1960, as that was the first year in history with 435 House seats (following Hawaii &amp;amp; Alaska’s addition to the United States).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
With this data, we first created a scatterplot based on the “Quarter 7 GDP Growth” and “President’s Party Seat Share.” GDP growth in Quarter 7 was chosen as the most recent quarter leading into an election. The expectation was that a recent bump (or lackthereof) in the economy would either benefit/hinder the president’s party in seat share (similar to what we read in Healy and Lenz || &amp;amp; Achens). To test, we formed the scatterplot while placing a linear regression model line on the graph itself.&lt;/p&gt;
&lt;p&gt;My personal expectations were that GDP growth would result in president’s party seat share being nearly 50% or above. Unfortunately, the model did not find the GDP growth and party seat share to follow my expectations. There were numerous instances where the president’s party’s seat share was below 50%, despite the GDP growth being around 1% or even more. Whenever the GDP growth was negative, the president’s party never received above 50% of the seat share.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
Then, we moved on to see if the president’s party’s vote share was more reflective than seat share, as described by the blog extension. When we ran the model, we did not find it to be particularly accurate, but there were instances (similar to seat share) of accuracy. Again, the economy and seat share relationship did not match expectations to the extent that was originally thought. Though similar to the president’s party seat share, it did reveal that there was not one instance where a president’s party won the majority of the popular vote when GDP growth was negative. This made sense.&lt;/p&gt;
&lt;p&gt;Then, we aimed to calculate the actual linear regression number on the GDP growth pct as it relates to president’s party vote vote share &amp;amp; president’s party seat share.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
To begin, we looked at the relationship at a quantified relationship between pres_party_vote_share and GDP_growth_pct. We found the calculation to be 3.65, thus indicating that for every 1% increase in GDP, we can expect the president’s party vote share to increase by 3.65%. I do think this number could be defending in traditional election circumstances, but the 15 midterm years we are utilizing for analysis make me somewhat uncertain about this. If I had the ability, I would use data from past midterms well beyond 1962, given that I had additional time &amp;amp; data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;
We then ran the other calculation. Our calculations found a value of 8.174 between a lm calculation of pres_party_seat_share and GDP_growth_pct. This means that for every 1% increase in GDP, we could expect an 8.17% increase in pres party’s seat share. However, I do not buy this number. This is such a large number that simply does not make much sense in the modern political world. A 1% increase will likely not result in an 8% increase in future elections, especially midterm ones with many more factors than the economy. While an interesting finding, I do not know if I trust it entirely. Similar to above, I would also wish to explore this with additional time &amp;amp; resources.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;https://example.com/post/blog-post-1/index.en_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;672&#34; /&gt;
The second part of this blog extension is to see if there is a change in accuracy over time in these elections. Plainly put: there does not appear to be.&lt;/p&gt;
&lt;p&gt;To determine this, we utilized a plot that mapped both a predicted model (based on our data) and the actual model. The party vote share based on actual results vs predicted results did find some spot-on accuracies in the elections of: 1974, 1982, 1990, and 2008. There were also some close calls, but on the overall, it was not nearly as predicitive as it could’ve been. Given the range of accuracy/innacuracies across the time frame, I believe that there is not a significant difference overtime.&lt;/p&gt;
&lt;p&gt;When applying this to seat share, predicted vs actual, there were spot on predictions but also many that missed the mark. Generally, there were not many points of consistent accuracy or consistent inaccuracies, as accuracy was a variety across the board.&lt;/p&gt;
&lt;p&gt;Main takeaways:
GDP growth does not seem to be the most predicitve/accurate indicator for a president’s seat growth or vote share
“It’s the economy, stupid.” may not be as true as we think
Time did not help the accuracy/predictive ability of our models&lt;/p&gt;
&lt;p&gt;Sources:
1. Achen and Bartels (2017)
2. Healy and Lenz (2014)
3. I did not use Wright as there was no unemployment calculations.&lt;/p&gt;
&lt;p&gt;Data being used:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;GDP growth (national): 1947-2022 (US Bureau of Economic Analysis, Department of Commerce)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Real disposable income (national): 1959-2022 (US Bureau of Economic Analysis)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inflation – CPI (national): 1947-2022 (US Bureau of Labor Statistics, Department of Labor)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unemployment (national): 1948-2022 (US Bureau of Labor Statistics)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unemployment (state): 1976-2022 (US Bureau of Labor Statistics)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
